{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Fp2TwAFR79K0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2f01a5-9730-4319-f463-702e741d968f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbLiB8bvxcOB"
      },
      "source": [
        "# **1 - Importando bibliotecas**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-learn --upgrade                                             # atualizar scikit learn\n",
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "metadata": {
        "id": "58SVpNM4B9cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSXdTe3dxaoI"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "from numpy import arange\n",
        "from scipy.stats import uniform, randint\n",
        "import pickle                                                                    #Módulo para salvar modelo\n",
        "import joblib                                                                    #Módulo para salvar o modelo\n",
        "import cv2                                                                       #Módulo para manipulação de imagens\n",
        "import numpy as np                                                               #Módulo para a manipulação de arrays\n",
        "import pandas as pd                                                              #Módulo para a manipulação de dataframes\n",
        "import matplotlib.pyplot as plt                                                  #Módulo para a manipulação de gráficos\n",
        "import os, glob                                                                  #Módulos para manipular estruturas de diretório\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis             #Módulo para a aplicação do LDA\n",
        "from sklearn.ensemble import RandomForestClassifier                              #Módulo para a aplicação do RF\n",
        "from sklearn.preprocessing import StandardScaler                                 #Normalização Min-Max e Padronização\n",
        "from sklearn.preprocessing import LabelEncoder                                   #Módulo para conversão de labels\n",
        "from sklearn.svm import SVC                                                      #Módulo para a aplicação do SVM\n",
        "from sklearn.neural_network import MLPClassifier                                 #Módulo para a aplicação do MLP\n",
        "from sklearn. model_selection import StratifiedGroupKFold                        #Módulo para a aplicação do K-Fold estratificado\n",
        "from sklearn.metrics import confusion_matrix, classification_report              #Módulo para a aplicação da matriz de confusão\n",
        "from sklearn.metrics import ConfusionMatrixDisplay                               #Módulo para a aplicação da matriz de confusão\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  #Métricas\n",
        "from sklearn.model_selection import RandomizedSearchCV                           #Módulo para a aplicação do Random Search\n",
        "from sklearn.metrics import make_scorer                                          #Módulo para a aplicação do Grid Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZatXweOmj9Df"
      },
      "source": [
        "# **2 - Importando os conjunto de features LBP**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "1hxQtA9yCdb6",
        "outputId": "7c5bbccb-3a3c-485a-feb5-47bd18a149fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(111850, 915)\n",
            "(28300, 915)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   Class  Sample  Patch      Id  V0_uni81  V1_uni81  V2_uni81  \\\n",
              "0      Apuleia leiocarpa      30      0  I_30_5      7467      6815      4177   \n",
              "1      Apuleia leiocarpa      30      1  I_30_5      8359      6965      4164   \n",
              "2      Apuleia leiocarpa      30      2  I_30_5      7894      6779      4296   \n",
              "3      Apuleia leiocarpa      30      3  I_30_5      8166      6920      4156   \n",
              "4      Apuleia leiocarpa      30      4  I_30_5      8150      6899      4103   \n",
              "...                  ...     ...    ...     ...       ...       ...       ...   \n",
              "28295   Vatairea sericea      62     45  C_62_8      6700      6259      4931   \n",
              "28296   Vatairea sericea      62     46  C_62_8      6264      6000      4940   \n",
              "28297   Vatairea sericea      62     47  C_62_8      6182      6087      4939   \n",
              "28298   Vatairea sericea      62     48  C_62_8      6179      5971      4820   \n",
              "28299   Vatairea sericea      62     49  C_62_8      6577      6267      4717   \n",
              "\n",
              "       V3_uni81  V4_uni81  V5_uni81  ...  V545_nri243  V546_nri243  \\\n",
              "0          4928      5296      4888  ...           92          202   \n",
              "1          4159      4030      4095  ...          133          313   \n",
              "2          4644      4611      4573  ...          122          315   \n",
              "3          4181      4325      4343  ...           85          245   \n",
              "4          4343      4418      4414  ...           98          265   \n",
              "...         ...       ...       ...  ...          ...          ...   \n",
              "28295      5884      6398      5748  ...          118          327   \n",
              "28296      6436      7045      6069  ...          125          319   \n",
              "28297      6551      6934      6073  ...          110          281   \n",
              "28298      6347      7207      6411  ...          124          346   \n",
              "28299      6007      6652      5808  ...          131          354   \n",
              "\n",
              "       V547_nri243  V548_nri243  V549_nri243  V550_nri243  V551_nri243  \\\n",
              "0               82           16          122           18           94   \n",
              "1              137           24          141           21          102   \n",
              "2              133           32          159           19           80   \n",
              "3               93           27          133           18          112   \n",
              "4               94           18          128           17           96   \n",
              "...            ...          ...          ...          ...          ...   \n",
              "28295          133           37          127           19           68   \n",
              "28296          152           51          115           14           53   \n",
              "28297          130           41          118           15           58   \n",
              "28298          167           53          130           24           49   \n",
              "28299          133           34          110           19           54   \n",
              "\n",
              "       V552_nri243  V553_nri243  V554_nri243  \n",
              "0              263         4965        38619  \n",
              "1              271         5059        40025  \n",
              "2              211         4764        39171  \n",
              "3              333         5074        39693  \n",
              "4              272         5013        39385  \n",
              "...            ...          ...          ...  \n",
              "28295          123         4343        37544  \n",
              "28296           93         4160        36302  \n",
              "28297          115         4199        36060  \n",
              "28298          108         4365        36519  \n",
              "28299           97         4182        37416  \n",
              "\n",
              "[28300 rows x 915 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27d1c3dd-3121-47be-b0af-e83173e383d8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class</th>\n",
              "      <th>Sample</th>\n",
              "      <th>Patch</th>\n",
              "      <th>Id</th>\n",
              "      <th>V0_uni81</th>\n",
              "      <th>V1_uni81</th>\n",
              "      <th>V2_uni81</th>\n",
              "      <th>V3_uni81</th>\n",
              "      <th>V4_uni81</th>\n",
              "      <th>V5_uni81</th>\n",
              "      <th>...</th>\n",
              "      <th>V545_nri243</th>\n",
              "      <th>V546_nri243</th>\n",
              "      <th>V547_nri243</th>\n",
              "      <th>V548_nri243</th>\n",
              "      <th>V549_nri243</th>\n",
              "      <th>V550_nri243</th>\n",
              "      <th>V551_nri243</th>\n",
              "      <th>V552_nri243</th>\n",
              "      <th>V553_nri243</th>\n",
              "      <th>V554_nri243</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apuleia leiocarpa</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>I_30_5</td>\n",
              "      <td>7467</td>\n",
              "      <td>6815</td>\n",
              "      <td>4177</td>\n",
              "      <td>4928</td>\n",
              "      <td>5296</td>\n",
              "      <td>4888</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>202</td>\n",
              "      <td>82</td>\n",
              "      <td>16</td>\n",
              "      <td>122</td>\n",
              "      <td>18</td>\n",
              "      <td>94</td>\n",
              "      <td>263</td>\n",
              "      <td>4965</td>\n",
              "      <td>38619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Apuleia leiocarpa</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>I_30_5</td>\n",
              "      <td>8359</td>\n",
              "      <td>6965</td>\n",
              "      <td>4164</td>\n",
              "      <td>4159</td>\n",
              "      <td>4030</td>\n",
              "      <td>4095</td>\n",
              "      <td>...</td>\n",
              "      <td>133</td>\n",
              "      <td>313</td>\n",
              "      <td>137</td>\n",
              "      <td>24</td>\n",
              "      <td>141</td>\n",
              "      <td>21</td>\n",
              "      <td>102</td>\n",
              "      <td>271</td>\n",
              "      <td>5059</td>\n",
              "      <td>40025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Apuleia leiocarpa</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>I_30_5</td>\n",
              "      <td>7894</td>\n",
              "      <td>6779</td>\n",
              "      <td>4296</td>\n",
              "      <td>4644</td>\n",
              "      <td>4611</td>\n",
              "      <td>4573</td>\n",
              "      <td>...</td>\n",
              "      <td>122</td>\n",
              "      <td>315</td>\n",
              "      <td>133</td>\n",
              "      <td>32</td>\n",
              "      <td>159</td>\n",
              "      <td>19</td>\n",
              "      <td>80</td>\n",
              "      <td>211</td>\n",
              "      <td>4764</td>\n",
              "      <td>39171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Apuleia leiocarpa</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>I_30_5</td>\n",
              "      <td>8166</td>\n",
              "      <td>6920</td>\n",
              "      <td>4156</td>\n",
              "      <td>4181</td>\n",
              "      <td>4325</td>\n",
              "      <td>4343</td>\n",
              "      <td>...</td>\n",
              "      <td>85</td>\n",
              "      <td>245</td>\n",
              "      <td>93</td>\n",
              "      <td>27</td>\n",
              "      <td>133</td>\n",
              "      <td>18</td>\n",
              "      <td>112</td>\n",
              "      <td>333</td>\n",
              "      <td>5074</td>\n",
              "      <td>39693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Apuleia leiocarpa</td>\n",
              "      <td>30</td>\n",
              "      <td>4</td>\n",
              "      <td>I_30_5</td>\n",
              "      <td>8150</td>\n",
              "      <td>6899</td>\n",
              "      <td>4103</td>\n",
              "      <td>4343</td>\n",
              "      <td>4418</td>\n",
              "      <td>4414</td>\n",
              "      <td>...</td>\n",
              "      <td>98</td>\n",
              "      <td>265</td>\n",
              "      <td>94</td>\n",
              "      <td>18</td>\n",
              "      <td>128</td>\n",
              "      <td>17</td>\n",
              "      <td>96</td>\n",
              "      <td>272</td>\n",
              "      <td>5013</td>\n",
              "      <td>39385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28295</th>\n",
              "      <td>Vatairea sericea</td>\n",
              "      <td>62</td>\n",
              "      <td>45</td>\n",
              "      <td>C_62_8</td>\n",
              "      <td>6700</td>\n",
              "      <td>6259</td>\n",
              "      <td>4931</td>\n",
              "      <td>5884</td>\n",
              "      <td>6398</td>\n",
              "      <td>5748</td>\n",
              "      <td>...</td>\n",
              "      <td>118</td>\n",
              "      <td>327</td>\n",
              "      <td>133</td>\n",
              "      <td>37</td>\n",
              "      <td>127</td>\n",
              "      <td>19</td>\n",
              "      <td>68</td>\n",
              "      <td>123</td>\n",
              "      <td>4343</td>\n",
              "      <td>37544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28296</th>\n",
              "      <td>Vatairea sericea</td>\n",
              "      <td>62</td>\n",
              "      <td>46</td>\n",
              "      <td>C_62_8</td>\n",
              "      <td>6264</td>\n",
              "      <td>6000</td>\n",
              "      <td>4940</td>\n",
              "      <td>6436</td>\n",
              "      <td>7045</td>\n",
              "      <td>6069</td>\n",
              "      <td>...</td>\n",
              "      <td>125</td>\n",
              "      <td>319</td>\n",
              "      <td>152</td>\n",
              "      <td>51</td>\n",
              "      <td>115</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>93</td>\n",
              "      <td>4160</td>\n",
              "      <td>36302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28297</th>\n",
              "      <td>Vatairea sericea</td>\n",
              "      <td>62</td>\n",
              "      <td>47</td>\n",
              "      <td>C_62_8</td>\n",
              "      <td>6182</td>\n",
              "      <td>6087</td>\n",
              "      <td>4939</td>\n",
              "      <td>6551</td>\n",
              "      <td>6934</td>\n",
              "      <td>6073</td>\n",
              "      <td>...</td>\n",
              "      <td>110</td>\n",
              "      <td>281</td>\n",
              "      <td>130</td>\n",
              "      <td>41</td>\n",
              "      <td>118</td>\n",
              "      <td>15</td>\n",
              "      <td>58</td>\n",
              "      <td>115</td>\n",
              "      <td>4199</td>\n",
              "      <td>36060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28298</th>\n",
              "      <td>Vatairea sericea</td>\n",
              "      <td>62</td>\n",
              "      <td>48</td>\n",
              "      <td>C_62_8</td>\n",
              "      <td>6179</td>\n",
              "      <td>5971</td>\n",
              "      <td>4820</td>\n",
              "      <td>6347</td>\n",
              "      <td>7207</td>\n",
              "      <td>6411</td>\n",
              "      <td>...</td>\n",
              "      <td>124</td>\n",
              "      <td>346</td>\n",
              "      <td>167</td>\n",
              "      <td>53</td>\n",
              "      <td>130</td>\n",
              "      <td>24</td>\n",
              "      <td>49</td>\n",
              "      <td>108</td>\n",
              "      <td>4365</td>\n",
              "      <td>36519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28299</th>\n",
              "      <td>Vatairea sericea</td>\n",
              "      <td>62</td>\n",
              "      <td>49</td>\n",
              "      <td>C_62_8</td>\n",
              "      <td>6577</td>\n",
              "      <td>6267</td>\n",
              "      <td>4717</td>\n",
              "      <td>6007</td>\n",
              "      <td>6652</td>\n",
              "      <td>5808</td>\n",
              "      <td>...</td>\n",
              "      <td>131</td>\n",
              "      <td>354</td>\n",
              "      <td>133</td>\n",
              "      <td>34</td>\n",
              "      <td>110</td>\n",
              "      <td>19</td>\n",
              "      <td>54</td>\n",
              "      <td>97</td>\n",
              "      <td>4182</td>\n",
              "      <td>37416</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28300 rows × 915 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27d1c3dd-3121-47be-b0af-e83173e383d8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27d1c3dd-3121-47be-b0af-e83173e383d8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27d1c3dd-3121-47be-b0af-e83173e383d8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-74a5966a-8a6a-48e0-8f08-5c381087149f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-74a5966a-8a6a-48e0-8f08-5c381087149f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-74a5966a-8a6a-48e0-8f08-5c381087149f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_5b280de3-3aa1-4049-8e9c-907e9cd87617\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_5b280de3-3aa1-4049-8e9c-907e9cd87617 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data_test"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# Importando todos os conjunto de dados - treino e teste\n",
        "# ================================================================================\n",
        "\n",
        "# Dados de treinamento (Pasta: Features/train)\n",
        "data_train = pd.concat((pd.read_csv(f, sep=',', encoding='utf-8') for f in glob.glob(\"./Output_patches/LBP/Features/train/*.csv\")), axis = 1)\n",
        "data_train = data_train.loc[:, ~data_train.columns.duplicated()]                                          # Elimina as colunas duplicadas\n",
        "data_train = data_train[ ['Class', \"Sample\", 'Patch', 'Id', 'Dev'] + [ col for col in data_train.columns if col not in ['Class', \"Sample\", 'Patch', 'Id', 'Dev'] ]]  # Reordena as colunas\n",
        "data_train['Id'] = data_train['Dev'] + '_' + data_train['Sample'].astype(str) + '_' + data_train['Id'].astype(str)\n",
        "data_train = data_train.drop(columns=['Dev'])\n",
        "print(data_train.shape)\n",
        "# display(data_train)\n",
        "\n",
        "\n",
        "\n",
        "# Dados de teste (Pasta: Fetures/Test)\n",
        "data_test = pd.concat((pd.read_csv(f, sep=',', encoding='utf-8') for f in glob.glob(\"./Output_patches/LBP/Features/test/*.csv\")), axis = 1)\n",
        "data_test = data_test.loc[:, ~data_test.columns.duplicated()]                                             # Elimina as colunas duplicadas\n",
        "data_test = data_test[ ['Class', \"Sample\", 'Patch', 'Id', 'Dev'] + [ col for col in data_test.columns if col not in ['Class', \"Sample\", 'Patch', 'Id', 'Dev'] ]]  # Reordena as colunas\n",
        "data_test['Id'] = data_test['Dev'] + '_' + data_test['Sample'].astype(str) + '_' + data_test['Id'].astype(str)\n",
        "data_test = data_test.drop(columns=['Dev'])\n",
        "print(data_test.shape)\n",
        "display(data_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxW7u6q2jCgP",
        "outputId": "dcb53fc9-12b9-418e-dbf0-9c12e6507b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de variáveis dos dados: 915\n",
            "Número de amostras: 28300\n",
            "Número de espécies: 16\n",
            "------------------------------------\n",
            "Número de imagens por: Class\n",
            "Apuleia leiocarpa            1550\n",
            "Astronium lecointei          1850\n",
            "Bagassa guianensis           1850\n",
            "Bowdichia nitida             1950\n",
            "Cedrela odorata              2000\n",
            "Dipteryx odorata             1500\n",
            "Erisma uncinatum             1600\n",
            "Goupia glabra                1650\n",
            "Hymenolobium heterocarpum    1800\n",
            "Mezilaurus itauba            1650\n",
            "Parkia pendula               1850\n",
            "Protium acrense              1900\n",
            "Qualea paraensis             1700\n",
            "Simarouba amara              2000\n",
            "Trattinnickia glaziovii      1800\n",
            "Vatairea sericea             1650\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# Informações sobre o conjunto de dados\n",
        "# ================================================================================\n",
        "#train\n",
        "# print(f'Número de variáveis dos dados: {data_train.shape[1]}')\n",
        "# print(f'Número de amostras: {data_train.shape[0]}')\n",
        "# print(f'Número de espécies: {data_train[\"Class\"].nunique()}')\n",
        "# print('---'*12)\n",
        "# print(f'Número de imagens por: {data_train.groupby(\"Class\").size()}')\n",
        "#test\n",
        "print(f'Número de variáveis dos dados: {data_test.shape[1]}')\n",
        "print(f'Número de amostras: {data_test.shape[0]}')\n",
        "print(f'Número de espécies: {data_test[\"Class\"].nunique()}')\n",
        "print('---'*12)\n",
        "print(f'Número de imagens por: {data_test.groupby(\"Class\").size()}')\n",
        "#print(data.info())\n",
        "#data.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gMkbR1Dyuzf"
      },
      "source": [
        "## 2.1- Dividindo variáveis X e y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "uNO0jBIwyzOm",
        "outputId": "4ebb9563-9949-432d-dd7d-8ba487e386d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (111850, 911) y_train shape: (111850, 3)\n",
            "x_test shape: (28300, 911) y_test shape: (28300, 4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       V0_uni81  V1_uni81  V2_uni81  V3_uni81  V4_uni81  V5_uni81  V6_uni81  \\\n",
              "0          7467      6815      4177      4928      5296      4888      4367   \n",
              "1          8359      6965      4164      4159      4030      4095      3878   \n",
              "2          7894      6779      4296      4644      4611      4573      4111   \n",
              "3          8166      6920      4156      4181      4325      4343      3997   \n",
              "4          8150      6899      4103      4343      4418      4414      4138   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "28295      6700      6259      4931      5884      6398      5748      4630   \n",
              "28296      6264      6000      4940      6436      7045      6069      4632   \n",
              "28297      6182      6087      4939      6551      6934      6073      4859   \n",
              "28298      6179      5971      4820      6347      7207      6411      4699   \n",
              "28299      6577      6267      4717      6007      6652      5808      4545   \n",
              "\n",
              "       V7_uni81  V8_uni81  V9_uni81  ...  V545_nri243  V546_nri243  \\\n",
              "0          6644      7852     13102  ...           92          202   \n",
              "1          7013      8678     14195  ...          133          313   \n",
              "2          6828      8238     13562  ...          122          315   \n",
              "3          6800      8609     14039  ...           85          245   \n",
              "4          6869      8368     13834  ...           98          265   \n",
              "...         ...       ...       ...  ...          ...          ...   \n",
              "28295      6191      6715     12080  ...          118          327   \n",
              "28296      6095      6521     11534  ...          125          319   \n",
              "28297      6053      6466     11392  ...          110          281   \n",
              "28298      5959      6543     11400  ...          124          346   \n",
              "28299      6226      6784     11953  ...          131          354   \n",
              "\n",
              "       V547_nri243  V548_nri243  V549_nri243  V550_nri243  V551_nri243  \\\n",
              "0               82           16          122           18           94   \n",
              "1              137           24          141           21          102   \n",
              "2              133           32          159           19           80   \n",
              "3               93           27          133           18          112   \n",
              "4               94           18          128           17           96   \n",
              "...            ...          ...          ...          ...          ...   \n",
              "28295          133           37          127           19           68   \n",
              "28296          152           51          115           14           53   \n",
              "28297          130           41          118           15           58   \n",
              "28298          167           53          130           24           49   \n",
              "28299          133           34          110           19           54   \n",
              "\n",
              "       V552_nri243  V553_nri243  V554_nri243  \n",
              "0              263         4965        38619  \n",
              "1              271         5059        40025  \n",
              "2              211         4764        39171  \n",
              "3              333         5074        39693  \n",
              "4              272         5013        39385  \n",
              "...            ...          ...          ...  \n",
              "28295          123         4343        37544  \n",
              "28296           93         4160        36302  \n",
              "28297          115         4199        36060  \n",
              "28298          108         4365        36519  \n",
              "28299           97         4182        37416  \n",
              "\n",
              "[28300 rows x 911 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd980e3a-13c8-4873-b21a-46494e4f6156\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V0_uni81</th>\n",
              "      <th>V1_uni81</th>\n",
              "      <th>V2_uni81</th>\n",
              "      <th>V3_uni81</th>\n",
              "      <th>V4_uni81</th>\n",
              "      <th>V5_uni81</th>\n",
              "      <th>V6_uni81</th>\n",
              "      <th>V7_uni81</th>\n",
              "      <th>V8_uni81</th>\n",
              "      <th>V9_uni81</th>\n",
              "      <th>...</th>\n",
              "      <th>V545_nri243</th>\n",
              "      <th>V546_nri243</th>\n",
              "      <th>V547_nri243</th>\n",
              "      <th>V548_nri243</th>\n",
              "      <th>V549_nri243</th>\n",
              "      <th>V550_nri243</th>\n",
              "      <th>V551_nri243</th>\n",
              "      <th>V552_nri243</th>\n",
              "      <th>V553_nri243</th>\n",
              "      <th>V554_nri243</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7467</td>\n",
              "      <td>6815</td>\n",
              "      <td>4177</td>\n",
              "      <td>4928</td>\n",
              "      <td>5296</td>\n",
              "      <td>4888</td>\n",
              "      <td>4367</td>\n",
              "      <td>6644</td>\n",
              "      <td>7852</td>\n",
              "      <td>13102</td>\n",
              "      <td>...</td>\n",
              "      <td>92</td>\n",
              "      <td>202</td>\n",
              "      <td>82</td>\n",
              "      <td>16</td>\n",
              "      <td>122</td>\n",
              "      <td>18</td>\n",
              "      <td>94</td>\n",
              "      <td>263</td>\n",
              "      <td>4965</td>\n",
              "      <td>38619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8359</td>\n",
              "      <td>6965</td>\n",
              "      <td>4164</td>\n",
              "      <td>4159</td>\n",
              "      <td>4030</td>\n",
              "      <td>4095</td>\n",
              "      <td>3878</td>\n",
              "      <td>7013</td>\n",
              "      <td>8678</td>\n",
              "      <td>14195</td>\n",
              "      <td>...</td>\n",
              "      <td>133</td>\n",
              "      <td>313</td>\n",
              "      <td>137</td>\n",
              "      <td>24</td>\n",
              "      <td>141</td>\n",
              "      <td>21</td>\n",
              "      <td>102</td>\n",
              "      <td>271</td>\n",
              "      <td>5059</td>\n",
              "      <td>40025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7894</td>\n",
              "      <td>6779</td>\n",
              "      <td>4296</td>\n",
              "      <td>4644</td>\n",
              "      <td>4611</td>\n",
              "      <td>4573</td>\n",
              "      <td>4111</td>\n",
              "      <td>6828</td>\n",
              "      <td>8238</td>\n",
              "      <td>13562</td>\n",
              "      <td>...</td>\n",
              "      <td>122</td>\n",
              "      <td>315</td>\n",
              "      <td>133</td>\n",
              "      <td>32</td>\n",
              "      <td>159</td>\n",
              "      <td>19</td>\n",
              "      <td>80</td>\n",
              "      <td>211</td>\n",
              "      <td>4764</td>\n",
              "      <td>39171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8166</td>\n",
              "      <td>6920</td>\n",
              "      <td>4156</td>\n",
              "      <td>4181</td>\n",
              "      <td>4325</td>\n",
              "      <td>4343</td>\n",
              "      <td>3997</td>\n",
              "      <td>6800</td>\n",
              "      <td>8609</td>\n",
              "      <td>14039</td>\n",
              "      <td>...</td>\n",
              "      <td>85</td>\n",
              "      <td>245</td>\n",
              "      <td>93</td>\n",
              "      <td>27</td>\n",
              "      <td>133</td>\n",
              "      <td>18</td>\n",
              "      <td>112</td>\n",
              "      <td>333</td>\n",
              "      <td>5074</td>\n",
              "      <td>39693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8150</td>\n",
              "      <td>6899</td>\n",
              "      <td>4103</td>\n",
              "      <td>4343</td>\n",
              "      <td>4418</td>\n",
              "      <td>4414</td>\n",
              "      <td>4138</td>\n",
              "      <td>6869</td>\n",
              "      <td>8368</td>\n",
              "      <td>13834</td>\n",
              "      <td>...</td>\n",
              "      <td>98</td>\n",
              "      <td>265</td>\n",
              "      <td>94</td>\n",
              "      <td>18</td>\n",
              "      <td>128</td>\n",
              "      <td>17</td>\n",
              "      <td>96</td>\n",
              "      <td>272</td>\n",
              "      <td>5013</td>\n",
              "      <td>39385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28295</th>\n",
              "      <td>6700</td>\n",
              "      <td>6259</td>\n",
              "      <td>4931</td>\n",
              "      <td>5884</td>\n",
              "      <td>6398</td>\n",
              "      <td>5748</td>\n",
              "      <td>4630</td>\n",
              "      <td>6191</td>\n",
              "      <td>6715</td>\n",
              "      <td>12080</td>\n",
              "      <td>...</td>\n",
              "      <td>118</td>\n",
              "      <td>327</td>\n",
              "      <td>133</td>\n",
              "      <td>37</td>\n",
              "      <td>127</td>\n",
              "      <td>19</td>\n",
              "      <td>68</td>\n",
              "      <td>123</td>\n",
              "      <td>4343</td>\n",
              "      <td>37544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28296</th>\n",
              "      <td>6264</td>\n",
              "      <td>6000</td>\n",
              "      <td>4940</td>\n",
              "      <td>6436</td>\n",
              "      <td>7045</td>\n",
              "      <td>6069</td>\n",
              "      <td>4632</td>\n",
              "      <td>6095</td>\n",
              "      <td>6521</td>\n",
              "      <td>11534</td>\n",
              "      <td>...</td>\n",
              "      <td>125</td>\n",
              "      <td>319</td>\n",
              "      <td>152</td>\n",
              "      <td>51</td>\n",
              "      <td>115</td>\n",
              "      <td>14</td>\n",
              "      <td>53</td>\n",
              "      <td>93</td>\n",
              "      <td>4160</td>\n",
              "      <td>36302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28297</th>\n",
              "      <td>6182</td>\n",
              "      <td>6087</td>\n",
              "      <td>4939</td>\n",
              "      <td>6551</td>\n",
              "      <td>6934</td>\n",
              "      <td>6073</td>\n",
              "      <td>4859</td>\n",
              "      <td>6053</td>\n",
              "      <td>6466</td>\n",
              "      <td>11392</td>\n",
              "      <td>...</td>\n",
              "      <td>110</td>\n",
              "      <td>281</td>\n",
              "      <td>130</td>\n",
              "      <td>41</td>\n",
              "      <td>118</td>\n",
              "      <td>15</td>\n",
              "      <td>58</td>\n",
              "      <td>115</td>\n",
              "      <td>4199</td>\n",
              "      <td>36060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28298</th>\n",
              "      <td>6179</td>\n",
              "      <td>5971</td>\n",
              "      <td>4820</td>\n",
              "      <td>6347</td>\n",
              "      <td>7207</td>\n",
              "      <td>6411</td>\n",
              "      <td>4699</td>\n",
              "      <td>5959</td>\n",
              "      <td>6543</td>\n",
              "      <td>11400</td>\n",
              "      <td>...</td>\n",
              "      <td>124</td>\n",
              "      <td>346</td>\n",
              "      <td>167</td>\n",
              "      <td>53</td>\n",
              "      <td>130</td>\n",
              "      <td>24</td>\n",
              "      <td>49</td>\n",
              "      <td>108</td>\n",
              "      <td>4365</td>\n",
              "      <td>36519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28299</th>\n",
              "      <td>6577</td>\n",
              "      <td>6267</td>\n",
              "      <td>4717</td>\n",
              "      <td>6007</td>\n",
              "      <td>6652</td>\n",
              "      <td>5808</td>\n",
              "      <td>4545</td>\n",
              "      <td>6226</td>\n",
              "      <td>6784</td>\n",
              "      <td>11953</td>\n",
              "      <td>...</td>\n",
              "      <td>131</td>\n",
              "      <td>354</td>\n",
              "      <td>133</td>\n",
              "      <td>34</td>\n",
              "      <td>110</td>\n",
              "      <td>19</td>\n",
              "      <td>54</td>\n",
              "      <td>97</td>\n",
              "      <td>4182</td>\n",
              "      <td>37416</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28300 rows × 911 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd980e3a-13c8-4873-b21a-46494e4f6156')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fd980e3a-13c8-4873-b21a-46494e4f6156 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fd980e3a-13c8-4873-b21a-46494e4f6156');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-846d8843-008e-451b-992b-db2b5f85dbaa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-846d8843-008e-451b-992b-db2b5f85dbaa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-846d8843-008e-451b-992b-db2b5f85dbaa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_4e5b1d91-6674-4719-88fe-50e6152e3ebe\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4e5b1d91-6674-4719-88fe-50e6152e3ebe button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_test"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# Divisão de variáveis\n",
        "# ================================================================================\n",
        "#Train\n",
        "X_train = data_train.filter(regex = '_')                                         # Separando os atributos\n",
        "y_train = data_train.filter(items = ['Class', \"Sample\", 'Patch'])                # Separando as classes\n",
        "z_train = data_train.filter(items = ['Id'])                                      # Separando as amostras\n",
        "\n",
        "#Test\n",
        "X_test = data_test.filter(regex = '_')                                           # Separando os atributos\n",
        "y_test = data_test.filter(items = ['Class', \"Sample\", 'Patch', 'Id'])            # Separando as classes\n",
        "#z_test = data_test.filter(items = ['Id'])                                       # Separando as amostras\n",
        "\n",
        "print(\"x_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
        "print(\"x_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
        "display(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c17-mqDQwop"
      },
      "outputs": [],
      "source": [
        "#-----------------------------------------------------------------------------#\n",
        "# Codificação dos patches\n",
        "#-----------------------------------------------------------------------------#\n",
        "'''Obs: Para obter uma divisão por amostra e rastrear as imagens foi criada uma função de codificação (LabelEnconder)'''\n",
        "\n",
        "def converter_variaveis_objeto_para_int(df):\n",
        "    # Inicialize o LabelEncoder\n",
        "    label_encoder = LabelEncoder()\n",
        "\n",
        "    # Itere sobre as colunas do DataFrame\n",
        "    for coluna in df.columns:\n",
        "        # Verifique se a coluna é do tipo 'object'\n",
        "        if df[coluna].dtype == 'object':\n",
        "            # Ajuste e transforme os dados usando o LabelEncoder\n",
        "            df[coluna] = label_encoder.fit_transform(df[coluna])\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "z_train = converter_variaveis_objeto_para_int(df = z_train)\n",
        "y_train = pd.concat([y_train, z_train], axis = 1)\n",
        "z_train = y_train['Sample'].astype(str) + '_' + y_train['Id'].astype(str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2afbgeO3oV-p"
      },
      "source": [
        "## 2.2- Normalização Z-score\n",
        "\n",
        "Deve-se normalizar/padronizar os dados para evitar o **'vazamento de dados'**, pois a normalização daria ao modelo informações adicionais sobre o conjunto de teste se normalizássemos todos os dados de uma vez."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "whgyFKdwoSqP",
        "outputId": "a8165d74-4398-4a68-aaf6-9592f4726377"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        V0_uni81  V1_uni81  V2_uni81  V3_uni81  V4_uni81  V5_uni81  V6_uni81  \\\n",
              "0      -1.178635 -0.900991  1.398945  0.707300  0.901720  1.044556  1.888438   \n",
              "1       0.795390  0.429917 -0.437833 -1.163413 -1.035687 -0.850823 -0.046917   \n",
              "2       0.659373  0.543792 -0.480351 -1.079878 -0.989123 -0.937340  0.205754   \n",
              "3      -0.424035 -0.156062  0.208441  0.043726  0.160849  0.614635  1.727158   \n",
              "4       0.011221  0.183189  0.324657 -0.436306 -0.452802 -0.361006  1.125048   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "111845  0.703135  1.419202 -0.749631 -0.810448 -0.683129 -0.917375 -0.933955   \n",
              "111846 -0.025445  0.776285 -0.403818 -0.512781  0.049427 -0.178656 -0.361412   \n",
              "111847 -0.899504  0.354001 -0.060840  0.349629  0.864302  0.659890  0.256826   \n",
              "111848  1.280322  1.729984 -1.815416 -1.394016 -1.093061 -1.250131 -0.966211   \n",
              "111849  1.211722  1.635089 -1.438423 -1.388133 -1.165402 -1.226173 -0.831811   \n",
              "\n",
              "        V7_uni81  V8_uni81  V9_uni81  ...  V545_nri243  V546_nri243  \\\n",
              "0      -0.917036 -0.830386 -0.957408  ...     0.625439    -0.542785   \n",
              "1       0.790536  0.560612  1.150006  ...    -0.470222    -0.109455   \n",
              "2       0.699100  0.614310  1.074110  ...    -0.470222    -0.165010   \n",
              "3       0.129909 -0.794242 -0.239934  ...    -0.130189    -0.798338   \n",
              "4       0.239633  0.106240  0.316924  ...    -0.356878    -0.509452   \n",
              "...          ...       ...       ...  ...          ...          ...   \n",
              "111845  1.149424  0.164069  0.844660  ...     0.927691     0.201653   \n",
              "111846  0.909403 -0.208722  0.252502  ...     1.116598     0.357207   \n",
              "111847  0.406504 -0.813863 -0.604408  ...     1.532194     0.457206   \n",
              "111848  1.487738  0.608114  1.224136  ...     1.192161     0.579427   \n",
              "111849  1.266005  0.575069  1.319446  ...     0.663221     0.390540   \n",
              "\n",
              "        V547_nri243  V548_nri243  V549_nri243  V550_nri243  V551_nri243  \\\n",
              "0          0.305550    -0.069983    -0.185130     0.837295     0.276414   \n",
              "1         -0.333531    -0.374987     0.768420     1.094744     0.964940   \n",
              "2          0.070099    -0.171651     0.564088     1.094744     0.491578   \n",
              "3         -0.299895    -0.578324    -0.082964    -0.321225    -0.756375   \n",
              "4          0.002827     0.641696     0.666254     0.708570     0.577644   \n",
              "...             ...          ...          ...          ...          ...   \n",
              "111845    -0.400802    -0.273319     0.121368    -0.964848     0.663710   \n",
              "111846     0.103735     0.438359    -0.559739    -0.707399     0.018217   \n",
              "111847    -0.737160    -0.984997    -0.219185    -0.578674    -0.412112   \n",
              "111848     0.036463    -0.374987     0.053258    -1.093572    -0.756375   \n",
              "111849     0.103735     1.048369     0.734365    -0.449950    -0.369079   \n",
              "\n",
              "        V552_nri243  V553_nri243  V554_nri243  \n",
              "0         -0.166309    -0.265040    -0.741065  \n",
              "1          0.600192    -0.066838     1.016942  \n",
              "2          0.696005     0.055029     1.026637  \n",
              "3         -0.275809    -0.602519    -0.081812  \n",
              "4          0.559130     0.154130     0.511730  \n",
              "...             ...          ...          ...  \n",
              "111845     0.586505    -0.267718     1.073496  \n",
              "111846    -0.029433    -0.453867     0.667926  \n",
              "111847    -0.179996    -0.406995    -0.253089  \n",
              "111848     0.107442    -0.196741     1.052490  \n",
              "111849     0.353817    -0.265040     1.001861  \n",
              "\n",
              "[111850 rows x 911 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-981a950a-8818-4291-b132-a9331f50471a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V0_uni81</th>\n",
              "      <th>V1_uni81</th>\n",
              "      <th>V2_uni81</th>\n",
              "      <th>V3_uni81</th>\n",
              "      <th>V4_uni81</th>\n",
              "      <th>V5_uni81</th>\n",
              "      <th>V6_uni81</th>\n",
              "      <th>V7_uni81</th>\n",
              "      <th>V8_uni81</th>\n",
              "      <th>V9_uni81</th>\n",
              "      <th>...</th>\n",
              "      <th>V545_nri243</th>\n",
              "      <th>V546_nri243</th>\n",
              "      <th>V547_nri243</th>\n",
              "      <th>V548_nri243</th>\n",
              "      <th>V549_nri243</th>\n",
              "      <th>V550_nri243</th>\n",
              "      <th>V551_nri243</th>\n",
              "      <th>V552_nri243</th>\n",
              "      <th>V553_nri243</th>\n",
              "      <th>V554_nri243</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.178635</td>\n",
              "      <td>-0.900991</td>\n",
              "      <td>1.398945</td>\n",
              "      <td>0.707300</td>\n",
              "      <td>0.901720</td>\n",
              "      <td>1.044556</td>\n",
              "      <td>1.888438</td>\n",
              "      <td>-0.917036</td>\n",
              "      <td>-0.830386</td>\n",
              "      <td>-0.957408</td>\n",
              "      <td>...</td>\n",
              "      <td>0.625439</td>\n",
              "      <td>-0.542785</td>\n",
              "      <td>0.305550</td>\n",
              "      <td>-0.069983</td>\n",
              "      <td>-0.185130</td>\n",
              "      <td>0.837295</td>\n",
              "      <td>0.276414</td>\n",
              "      <td>-0.166309</td>\n",
              "      <td>-0.265040</td>\n",
              "      <td>-0.741065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.795390</td>\n",
              "      <td>0.429917</td>\n",
              "      <td>-0.437833</td>\n",
              "      <td>-1.163413</td>\n",
              "      <td>-1.035687</td>\n",
              "      <td>-0.850823</td>\n",
              "      <td>-0.046917</td>\n",
              "      <td>0.790536</td>\n",
              "      <td>0.560612</td>\n",
              "      <td>1.150006</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.470222</td>\n",
              "      <td>-0.109455</td>\n",
              "      <td>-0.333531</td>\n",
              "      <td>-0.374987</td>\n",
              "      <td>0.768420</td>\n",
              "      <td>1.094744</td>\n",
              "      <td>0.964940</td>\n",
              "      <td>0.600192</td>\n",
              "      <td>-0.066838</td>\n",
              "      <td>1.016942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.659373</td>\n",
              "      <td>0.543792</td>\n",
              "      <td>-0.480351</td>\n",
              "      <td>-1.079878</td>\n",
              "      <td>-0.989123</td>\n",
              "      <td>-0.937340</td>\n",
              "      <td>0.205754</td>\n",
              "      <td>0.699100</td>\n",
              "      <td>0.614310</td>\n",
              "      <td>1.074110</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.470222</td>\n",
              "      <td>-0.165010</td>\n",
              "      <td>0.070099</td>\n",
              "      <td>-0.171651</td>\n",
              "      <td>0.564088</td>\n",
              "      <td>1.094744</td>\n",
              "      <td>0.491578</td>\n",
              "      <td>0.696005</td>\n",
              "      <td>0.055029</td>\n",
              "      <td>1.026637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.424035</td>\n",
              "      <td>-0.156062</td>\n",
              "      <td>0.208441</td>\n",
              "      <td>0.043726</td>\n",
              "      <td>0.160849</td>\n",
              "      <td>0.614635</td>\n",
              "      <td>1.727158</td>\n",
              "      <td>0.129909</td>\n",
              "      <td>-0.794242</td>\n",
              "      <td>-0.239934</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.130189</td>\n",
              "      <td>-0.798338</td>\n",
              "      <td>-0.299895</td>\n",
              "      <td>-0.578324</td>\n",
              "      <td>-0.082964</td>\n",
              "      <td>-0.321225</td>\n",
              "      <td>-0.756375</td>\n",
              "      <td>-0.275809</td>\n",
              "      <td>-0.602519</td>\n",
              "      <td>-0.081812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011221</td>\n",
              "      <td>0.183189</td>\n",
              "      <td>0.324657</td>\n",
              "      <td>-0.436306</td>\n",
              "      <td>-0.452802</td>\n",
              "      <td>-0.361006</td>\n",
              "      <td>1.125048</td>\n",
              "      <td>0.239633</td>\n",
              "      <td>0.106240</td>\n",
              "      <td>0.316924</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.356878</td>\n",
              "      <td>-0.509452</td>\n",
              "      <td>0.002827</td>\n",
              "      <td>0.641696</td>\n",
              "      <td>0.666254</td>\n",
              "      <td>0.708570</td>\n",
              "      <td>0.577644</td>\n",
              "      <td>0.559130</td>\n",
              "      <td>0.154130</td>\n",
              "      <td>0.511730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111845</th>\n",
              "      <td>0.703135</td>\n",
              "      <td>1.419202</td>\n",
              "      <td>-0.749631</td>\n",
              "      <td>-0.810448</td>\n",
              "      <td>-0.683129</td>\n",
              "      <td>-0.917375</td>\n",
              "      <td>-0.933955</td>\n",
              "      <td>1.149424</td>\n",
              "      <td>0.164069</td>\n",
              "      <td>0.844660</td>\n",
              "      <td>...</td>\n",
              "      <td>0.927691</td>\n",
              "      <td>0.201653</td>\n",
              "      <td>-0.400802</td>\n",
              "      <td>-0.273319</td>\n",
              "      <td>0.121368</td>\n",
              "      <td>-0.964848</td>\n",
              "      <td>0.663710</td>\n",
              "      <td>0.586505</td>\n",
              "      <td>-0.267718</td>\n",
              "      <td>1.073496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111846</th>\n",
              "      <td>-0.025445</td>\n",
              "      <td>0.776285</td>\n",
              "      <td>-0.403818</td>\n",
              "      <td>-0.512781</td>\n",
              "      <td>0.049427</td>\n",
              "      <td>-0.178656</td>\n",
              "      <td>-0.361412</td>\n",
              "      <td>0.909403</td>\n",
              "      <td>-0.208722</td>\n",
              "      <td>0.252502</td>\n",
              "      <td>...</td>\n",
              "      <td>1.116598</td>\n",
              "      <td>0.357207</td>\n",
              "      <td>0.103735</td>\n",
              "      <td>0.438359</td>\n",
              "      <td>-0.559739</td>\n",
              "      <td>-0.707399</td>\n",
              "      <td>0.018217</td>\n",
              "      <td>-0.029433</td>\n",
              "      <td>-0.453867</td>\n",
              "      <td>0.667926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111847</th>\n",
              "      <td>-0.899504</td>\n",
              "      <td>0.354001</td>\n",
              "      <td>-0.060840</td>\n",
              "      <td>0.349629</td>\n",
              "      <td>0.864302</td>\n",
              "      <td>0.659890</td>\n",
              "      <td>0.256826</td>\n",
              "      <td>0.406504</td>\n",
              "      <td>-0.813863</td>\n",
              "      <td>-0.604408</td>\n",
              "      <td>...</td>\n",
              "      <td>1.532194</td>\n",
              "      <td>0.457206</td>\n",
              "      <td>-0.737160</td>\n",
              "      <td>-0.984997</td>\n",
              "      <td>-0.219185</td>\n",
              "      <td>-0.578674</td>\n",
              "      <td>-0.412112</td>\n",
              "      <td>-0.179996</td>\n",
              "      <td>-0.406995</td>\n",
              "      <td>-0.253089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111848</th>\n",
              "      <td>1.280322</td>\n",
              "      <td>1.729984</td>\n",
              "      <td>-1.815416</td>\n",
              "      <td>-1.394016</td>\n",
              "      <td>-1.093061</td>\n",
              "      <td>-1.250131</td>\n",
              "      <td>-0.966211</td>\n",
              "      <td>1.487738</td>\n",
              "      <td>0.608114</td>\n",
              "      <td>1.224136</td>\n",
              "      <td>...</td>\n",
              "      <td>1.192161</td>\n",
              "      <td>0.579427</td>\n",
              "      <td>0.036463</td>\n",
              "      <td>-0.374987</td>\n",
              "      <td>0.053258</td>\n",
              "      <td>-1.093572</td>\n",
              "      <td>-0.756375</td>\n",
              "      <td>0.107442</td>\n",
              "      <td>-0.196741</td>\n",
              "      <td>1.052490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111849</th>\n",
              "      <td>1.211722</td>\n",
              "      <td>1.635089</td>\n",
              "      <td>-1.438423</td>\n",
              "      <td>-1.388133</td>\n",
              "      <td>-1.165402</td>\n",
              "      <td>-1.226173</td>\n",
              "      <td>-0.831811</td>\n",
              "      <td>1.266005</td>\n",
              "      <td>0.575069</td>\n",
              "      <td>1.319446</td>\n",
              "      <td>...</td>\n",
              "      <td>0.663221</td>\n",
              "      <td>0.390540</td>\n",
              "      <td>0.103735</td>\n",
              "      <td>1.048369</td>\n",
              "      <td>0.734365</td>\n",
              "      <td>-0.449950</td>\n",
              "      <td>-0.369079</td>\n",
              "      <td>0.353817</td>\n",
              "      <td>-0.265040</td>\n",
              "      <td>1.001861</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111850 rows × 911 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-981a950a-8818-4291-b132-a9331f50471a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-981a950a-8818-4291-b132-a9331f50471a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-981a950a-8818-4291-b132-a9331f50471a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-701f6e63-cf63-4c54-a744-bb6150b41467\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-701f6e63-cf63-4c54-a744-bb6150b41467')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-701f6e63-cf63-4c54-a744-bb6150b41467 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d211b90a-7d60-4fe9-bfe8-e2f0d4ac6f4a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('X_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d211b90a-7d60-4fe9-bfe8-e2f0d4ac6f4a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('X_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ================================================================================\n",
        "# Normalização Z-score\n",
        "# ================================================================================\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
        "X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
        "display(X_train)\n",
        "#display(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-D6wxBnUpUy"
      },
      "source": [
        "# **3- Treinando os classificadores**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2q9EpuAR45v"
      },
      "source": [
        "### **3.1- Separa as features extraídas por cada operador**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k9CXOlnMY8f"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Separa as features extraídas por cada operador (LBP)- Conjunto de Treino\n",
        "# ================================================================================\n",
        "\n",
        "y_train[\"Class\"]  #labels\n",
        "\n",
        "# Features: Local Binary Pattern\n",
        "X_train_u = X_train.filter(like = 'uni')            # LBP Uniforme (3 combinações) (54 features)\n",
        "X_train_u81 = X_train.filter(regex = 'uni81')       # LBP Uniforme (P = 8, R = 1)  (10 features)\n",
        "X_train_u162 = X_train.filter(regex = 'uni162')     # LBP Uniforme (P = 16, R = 2) (18 features)\n",
        "X_train_u243 = X_train.filter(regex = 'uni243')     # LBP Uniforme (P = 24, R = 3) (26 features)\n",
        "\n",
        "X_train_nri = X_train.filter(like = 'nri')           # LBP NRI (3 combinações) (857 features)\n",
        "X_train_nri81 = X_train.filter(regex = 'nri81')      # LBP NRI (P = 8, R = 1)  (59 features)\n",
        "X_train_nri162 = X_train.filter(regex = 'nri162')    # LBP NRI (P = 16, R = 2) (243 features)\n",
        "X_train_nri243 = X_train.filter(regex = 'nri243')    # LBP NRI (P = 24, R = 3) (555 features)\n",
        "\n",
        "X_train_unri = X_train.filter(regex = r'uni|nri') # LBP Uniforme e LBP NRI (857 + 54 = 911)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j__FwWEya4mD"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Separa as features extraídas por cada operador (LBP) - Conjunto de Teste\n",
        "# ================================================================================\n",
        "\n",
        "y_test[\"Class\"]     #labels\n",
        "\n",
        "# Features: Local Binary Pattern\n",
        "X_test_u = X_test.filter(like = 'uni')            # LBP Uniforme (3 combinações) (54 features)\n",
        "X_test_u81 = X_test.filter(regex = 'uni81')       # LBP Uniforme (P = 8, R = 1)  (10 features)\n",
        "X_test_u162 = X_test.filter(regex = 'uni162')     # LBP Uniforme (P = 16, R = 2) (18 features)\n",
        "X_test_u243 = X_test.filter(regex = 'uni243')     # LBP Uniforme (P = 24, R = 3) (26 features)\n",
        "\n",
        "X_test_nri = X_test.filter(like = 'nri')           # LBP NRI (3 combinações) (857 features)\n",
        "X_test_nri81 = X_test.filter(regex = 'nri81')      # LBP NRI (P = 8, R = 1)  (59 features)\n",
        "X_test_nri162 = X_test.filter(regex = 'nri162')    # LBP NRI (P = 16, R = 2) (243 features)\n",
        "X_test_nri243 = X_test.filter(regex = 'nri243')    # LBP NRI (P = 24, R = 3) (555 features)\n",
        "\n",
        "X_test_unri = X_test.filter(regex = r'uni|nri') # LBP Uniforme e LBP NRI (857 + 54 = 911)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_T4bCkxYWIRO"
      },
      "source": [
        "### **3.2 - Configuraçoes de treinamento** (Todos os modelos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc0Pm0bzlfdR"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Configurações do treinamento\n",
        "# ================================================================================\n",
        "\n",
        "# Define Stratified Group 10-fold cross-validation\n",
        "cv = StratifiedGroupKFold(n_splits = 10, random_state = 42, shuffle = True)\n",
        "\n",
        "# Salvando o modelo (Pasta: Models/)\n",
        "def save_model_pickle(model, model_name):\n",
        "    with open(f'./Output_patches/LBP/Models/{model_name}.pickle', \"wb\") as file:\n",
        "        pickle.dump(model, file)\n",
        "\n",
        "def save_model_joblib(model, model_name):\n",
        "    with open(f'./Output_patches/LBP/Models/{model_name}.joblib', \"wb\") as file:\n",
        "        joblib.dump(model, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0w1CcyDk9gQ"
      },
      "source": [
        "### **3.3 - Suporte Vector Classifier - SVC**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ub6t6EIiqvts"
      },
      "source": [
        "#### **Modelo C1**: Usando features LBP Uniforme (P = 8, R = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JWy1s3tohhO"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_u81_svc = pickle.load(open(\"./Output/Models_LBP/rs_u81_svc.pickle\", \"rb\"))\n",
        "best_u81_svc = rs_u81_svc.best_estimator_\n",
        "best_u81_svc.get_params()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u81, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u81.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u81.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u81.iloc[train_index], X_train_u81.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u81_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u81_svc.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u81_svc.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u81_svc, 'best_u81_svc')\n",
        "save_model_joblib(best_u81_svc, 'best_u81_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "AnMgmc_Zwtkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq1INNVl72IJ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJSipfSO72IJ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u81_svc = best_u81_svc.predict_proba(X_test_u81)\n",
        "prob_u81_svc = pd.DataFrame(prob_u81_svc, columns = best_u81_svc.classes_)\n",
        "class_value = prob_u81_svc.idxmax(axis=1)\n",
        "prob_value = prob_u81_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u81_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u81_svc = pd.concat([y_test, prob_u81_svc], axis = 1)\n",
        "prob_u81_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fho86PjP72IJ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u81_svc = prob_u81_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u81_svc = soma_prob_u81_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u81_svc = prob_u81_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u81_svc = pd.DataFrame({'Id': class_u81_svc.index,\n",
        "                          'Probabilidade': soma_prob_u81_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u81_svc.values,\n",
        "                          'Classe_Observada': class_obs_u81_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u81_svc = resultado_u81_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u81_svc['Classe_Predita'] = resultado_u81_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u81_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJheD0dq72IJ"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u81_svc['Classe_Observada'], resultado_u81_svc['Classe_Predita']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtvBK3Ii72IK"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - conjunto de teste (n = 566)\n",
        "# ================================================================================\n",
        "\n",
        "cm_u81_svc = confusion_matrix(resultado_u81_svc['Classe_Observada'], resultado_u81_svc['Classe_Predita'])\n",
        "disp_u81_svc = ConfusionMatrixDisplay(confusion_matrix = cm_u81_svc, display_labels = best_u81_svc.classes_)\n",
        "disp_u81_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u81_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u81_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u81_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u81_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_u81_svc', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Fk7FiYreEvR"
      },
      "source": [
        "#### **Modelo C2**: Usando features LBP Uniforme (P = 16, R = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_u162_svc = pickle.load(open(\"./Output/Models_LBP/rs_u162_svc.pickle\", \"rb\"))\n",
        "best_u162_svc = rs_u162_svc.best_estimator_\n",
        "best_u162_svc.get_params()"
      ],
      "metadata": {
        "id": "ofklEpmlzjz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u162, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u162.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u162.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u162.iloc[train_index], X_train_u162.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u162_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u162_svc.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u162_svc.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u162_svc, 'best_u162_svc')\n",
        "save_model_joblib(best_u162_svc, 'best_u162_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "gpLuh44kzZxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb1qEBca72IL"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9_P9zXm72IL"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u162_svc = best_u162_svc.predict_proba(X_test_u162)\n",
        "prob_u162_svc = pd.DataFrame(prob_u162_svc, columns = best_u162_svc.classes_)\n",
        "class_value = prob_u162_svc.idxmax(axis=1)\n",
        "prob_value = prob_u162_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u162_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u162_svc = pd.concat([y_test, prob_u162_svc], axis = 1)\n",
        "prob_u162_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUavujwr72IL"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u162_svc = prob_u162_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u162_svc = soma_prob_u162_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u162_svc = prob_u162_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u162_svc = pd.DataFrame({'Id': class_u162_svc.index,\n",
        "                          'Probabilidade': soma_prob_u162_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u162_svc.values,\n",
        "                          'Classe_Observada': class_obs_u162_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u162_svc = resultado_u162_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u162_svc['Classe_Predita'] = resultado_u162_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u162_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF1svWzy72IL"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u162_svc['Classe_Observada'], resultado_u162_svc['Classe_Predita']), target_names= best_u162_svc.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNxZn3MA72IL"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "\n",
        "cm_u162_svc = confusion_matrix(resultado_u162_svc['Classe_Observada'], resultado_u162_svc['Classe_Predita'])\n",
        "disp_u162_svc = ConfusionMatrixDisplay(confusion_matrix = cm_u162_svc, display_labels = best_u162_svc.classes_)\n",
        "disp_u162_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u162_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u162_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u162_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u162_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_u162_svc', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOTRWhRWlUWG"
      },
      "source": [
        "#### **Modelo C3**: Usando features LBP Uniforme (P = 24, R = 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_u243_svc = pickle.load(open(\"./Output/LBP/Models/SVC/rs_u243_svc.pickle\", \"rb\"))\n",
        "best_u243_svc = rs_u243_svc.best_estimator_\n",
        "best_u243_svc.get_params()"
      ],
      "metadata": {
        "id": "hvQx_tkP3XWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u243, y_train, groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u243.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u243.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u243.iloc[train_index], X_train_u243.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u243_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u243_svc.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u243_svc.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u243_svc, 'best_u243_svc')\n",
        "save_model_joblib(best_u243_svc, 'best_u243_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "7h3lhvKR3bRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU6LnGDS72IQ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deH7OaZU72IQ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u243_svc = best_u243_svc.predict_proba(X_test_u243)\n",
        "prob_u243_svc = pd.DataFrame(prob_u243_svc, columns = best_u243_svc.classes_)\n",
        "class_value = prob_u243_svc.idxmax(axis=1)\n",
        "prob_value = prob_u243_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u243_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u243_svc = pd.concat([y_test, prob_u243_svc], axis = 1)\n",
        "prob_u243_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br1Pbn6d72IQ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n = 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u243_svc = prob_u243_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u243_svc = soma_prob_u243_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u243_svc = prob_u243_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u243_svc = pd.DataFrame({'Id': class_u243_svc.index,\n",
        "                          'Probabilidade': soma_prob_u243_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u243_svc.values,\n",
        "                          'Classe_Observada': class_obs_u243_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u243_svc = resultado_u243_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u243_svc['Classe_Predita'] = resultado_u243_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u243_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bf2zlkRz72IQ"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u243_svc['Classe_Observada'], resultado_u243_svc['Classe_Predita']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2JvjnqI72IQ"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u243_svc = confusion_matrix(resultado_u243_svc['Classe_Observada'], resultado_u243_svc['Classe_Predita'])\n",
        "disp_u243_svc = ConfusionMatrixDisplay(confusion_matrix = cm_u243_svc, display_labels = best_u243_svc.classes_)\n",
        "disp_u243_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u243_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u243_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u243_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u243_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/SVC/cm_u243_svc', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjsaGYjHxCvo"
      },
      "source": [
        "#### **Modelo C4**: Usando features LBP Uniforme (Todos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_uni_svc = pickle.load(open(\"./Output/LBP/Models/SVC/rs_uni_svc.pickle\", \"rb\"))\n",
        "best_uni_svc = rs_uni_svc.best_estimator_\n",
        "best_uni_svc.get_params()"
      ],
      "metadata": {
        "id": "8ViV9yxV4i4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u, y_train, groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u.iloc[train_index], X_train_u.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_uni_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_uni_svc.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_uni_svc.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_uni_svc, 'best_uni_svc')\n",
        "save_model_joblib(best_uni_svc, 'best_uni_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "lWvLr1H94w3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SF10Neb072IR"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSGKVZRI72IR"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_uni_svc = best_uni_svc.predict_proba(X_test_u)\n",
        "prob_uni_svc = pd.DataFrame(prob_uni_svc, columns = best_uni_svc.classes_)\n",
        "class_value = prob_uni_svc.idxmax(axis=1)\n",
        "prob_value = prob_uni_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_uni_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_uni_svc = pd.concat([y_test, prob_uni_svc], axis = 1)\n",
        "prob_uni_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOmaXuX472IR"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_uni_svc = prob_uni_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_uni_svc = soma_prob_uni_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_uni_svc = prob_uni_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_uni_svc = pd.DataFrame({'Id': class_uni_svc.index,\n",
        "                          'Probabilidade': soma_prob_uni_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_uni_svc.values,\n",
        "                          'Classe_Observada': class_obs_uni_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_uni_svc = resultado_uni_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_uni_svc['Classe_Predita'] = resultado_uni_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_uni_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJkwBA_A72IR"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_uni_svc['Classe_Observada'], resultado_uni_svc['Classe_Predita']), target_names = best_uni_svc.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdBaWT_W72IR"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "\n",
        "cm_uni_svc = confusion_matrix(resultado_uni_svc['Classe_Observada'], resultado_uni_svc['Classe_Predita'])\n",
        "disp_uni_svc = ConfusionMatrixDisplay(confusion_matrix = cm_uni_svc, display_labels = best_uni_svc.classes_)\n",
        "disp_uni_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_uni_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_uni_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_uni_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_uni_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_uni_svc', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGQMwve86eCF"
      },
      "source": [
        "#### **Modelo C5**: Usando features LBP Uniforme Não Invariante (P = 8, R = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri81_svc = pickle.load(open(\"./Models_LBP/rs_nri81_svc.pickle\", \"rb\"))\n",
        "best_nri81_svc = rs_nri81_svc.best_estimator_\n",
        "best_nri81_svc.get_params()"
      ],
      "metadata": {
        "id": "iq4M6xsf5uPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri81, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri81.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri81.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri81.iloc[train_index], X_train_nri81.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri81_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri81_svc.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri81_svc.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri81_svc, 'best_nri81_svc')\n",
        "save_model_joblib(best_nri81_svc, 'best_nri81_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "be3SKb8F6CPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl7FFBp672IS"
      },
      "outputs": [],
      "source": [
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq5-6-_B72IT"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri81_svc = best_nri81_svcc.predict_proba(X_test_nri81)\n",
        "prob_nri81_svc = pd.DataFrame(prob_nri81_svc, columns = best_nri81_svc.classes_)\n",
        "class_value = prob_nri81_svc.idxmax(axis=1)\n",
        "prob_value = prob_nri81_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri81_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri81_svc = pd.concat([y_test, prob_nri81_svc], axis = 1)\n",
        "prob_nri81_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yz0X3ARK72IT"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri81_svc = prob_nri81_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri81_svc = soma_prob_nri81_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri81_svc = prob_nri81_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri81_svc = pd.DataFrame({'Id': class_nri81_svc.index,\n",
        "                          'Probabilidade': soma_prob_nri81_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri81_svc.values,\n",
        "                          'Classe_Observada': class_obs_nri81_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri81_svc = resultado_nri81_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri81_svc['Classe_Predita'] = resultado_nri81_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri81_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrQDckFk72IT"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n= 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri81_svc['Classe_Observada'], resultado_nri81_svc['Classe_Predita']), target_names = best_nri81_svc.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6r7Cm2aq72IT"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "\n",
        "cm_nri81_svc = confusion_matrix(resultado_nri81_svc['Classe_Observada'], resultado_nri81_svc['Classe_Predita'])\n",
        "disp_nri81_svc = ConfusionMatrixDisplay(confusion_matrix = cm_nri81_svc, display_labels= best_nri81_svc.classes_)\n",
        "disp_nri81_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri81_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri81_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri81_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri81_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri81_svc', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ya7JDI5BtZu"
      },
      "source": [
        "#### **Modelo C6**: Usando features LBP Uniforme Não Invariante (P = 16, R = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri162_svc = pickle.load(open(\"./Output/LBP/Models/SVC/rs_nri162_svc.pickle\", \"rb\"))\n",
        "best_nri162_svc = rs_nri162_svc.best_estimator_\n",
        "best_nri162_svc.get_params()"
      ],
      "metadata": {
        "id": "S2CHWLPY7mcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri162, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri162.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri162.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri162.iloc[train_index], X_train_nri162.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri162_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri162_svc.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri162_svc.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri162_svc, 'best_nri162_svc')\n",
        "save_model_joblib(best_nri162_svc, 'best_nri162_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "LK8HqR_w7nV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YG9N0Ab72IV"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y2ec8s_72IV"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri162_svc = best_nri162_svc.predict_proba(X_test_nri162)\n",
        "prob_nri162_svc = pd.DataFrame(prob_nri162_svc, columns = best_nri162_svc.classes_)\n",
        "class_value = prob_nri162_svc.idxmax(axis=1)\n",
        "prob_value = prob_nri162_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri162_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri162_svc = pd.concat([y_test, prob_nri162_svc], axis = 1)\n",
        "prob_nri162_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb-pBYWc72IV"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri162_svc = prob_nri162_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri162_svc = soma_prob_nri162_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri162_svc = prob_nri162_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri162_svc = pd.DataFrame({'Id': class_nri162_svc.index,\n",
        "                          'Probabilidade': soma_prob_nri162_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri162_svc.values,\n",
        "                          'Classe_Observada': class_obs_nri162_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri162_svc = resultado_nri162_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri162_svc['Classe_Predita'] = resultado_nri162_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri162_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43G9xko872IV"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri162_svc['Classe_Observada'], resultado_nri162_svc['Classe_Predita']), target_names = best_nri162_svc.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lt5aqEzJ72IV"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "\n",
        "cm_nri162_svc = confusion_matrix(resultado_nri162_svc['Classe_Observada'], resultado_nri162_svc['Classe_Predita'])\n",
        "disp_nri162_svc = ConfusionMatrixDisplay(confusion_matrix = cm_nri162_svc, display_labels= best_nri162_svc.classes_)\n",
        "disp_nri162_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri162_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri162_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri162_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri162_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri162_svc', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K59mwtlx1kTh"
      },
      "source": [
        "#### **Modelo C7**: Usando features LBP Uniforme Não Invariante (P = 24, R = 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri243_svc = pickle.load(open(\"./Output/LBP/Models/SVC/rs_nri243_svc.pickle\", \"rb\"))\n",
        "best_nri243_svc = rs_nri243_svc.best_estimator_\n",
        "best_nri243_svc.get_params()"
      ],
      "metadata": {
        "id": "faH3dCd28txm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri243, y_train, groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri243.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri243.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri243.iloc[train_index], X_train_nri243.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri243_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri243_svc.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri243_svc.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri243_svc, 'best_nri243_svc')\n",
        "save_model_joblib(best_nri243_svc, 'best_nri243_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "7zpeHe5Y8tlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbIaaMo372IW"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-sPeocd72IW"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri243_svc = best_nri243_svc.predict_proba(X_test_nri243)\n",
        "prob_nri243_svc = pd.DataFrame(prob_nri243_svc, columns = best_nri243_svc.classes_)\n",
        "class_value = prob_nri243_svc.idxmax(axis=1)\n",
        "prob_value = prob_nri243_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri243_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri243_svc = pd.concat([y_test, prob_nri243_svc], axis = 1)\n",
        "prob_nri243_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmXygX3j72IW"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n = 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri243_svc = prob_nri243_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri243_svc = soma_prob_nri243_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri243_svc = prob_nri243_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri243_svc = pd.DataFrame({'Id': class_nri243_svc.index,\n",
        "                          'Probabilidade': soma_prob_nri243_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri243_svc.values,\n",
        "                          'Classe_Observada': class_obs_nri243_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri243_svc = resultado_nri243_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri243_svc['Classe_Predita'] = resultado_nri243_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri243_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0228DtJE72IW"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri243_svc['Classe_Observada'], resultado_nri243_svc['Classe_Predita']), target_names = best_nri243_svc.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XM2mMStr72IW"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "\n",
        "cm_nri243_svc = confusion_matrix(resultado_nri243_svc['Classe_Observada'], resultado_nri243_svc['Classe_Predita'])\n",
        "disp_nri243_svc = ConfusionMatrixDisplay(confusion_matrix = cm_nri243_svc, display_labels= best_nri243_svc.classes_)\n",
        "disp_nri243_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri243_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri243_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri243_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri243_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri243_svc', dpi=800, bbox_inches='tight')\n",
        "plt.svc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUzgOLPh-oB2"
      },
      "source": [
        "#### **Modelo C8**: Usando features LBP Uniforme Não Invariante (Todos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri_svc = pickle.load(open(\"./Models_LBP/rs_nri_svc.pickle\", \"rb\"))\n",
        "best_nri_svc = rs_nri_svc.best_estimator_\n",
        "best_nri_svc.get_params()"
      ],
      "metadata": {
        "id": "UBY6cgq29w1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Código adaptado para extrair matrizes de confusão por fold'''\n",
        "\n",
        "model_name = 'best_nri_svc'\n",
        "\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes divisão: {X_train_nri.shape}')\n",
        "  print(f'Conjunto de validação antes divisão: {X_train_nri.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri.iloc[train_index], X_train_nri.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1}>>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri_svc.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri_svc.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "  cm = confusion_matrix(fold_obs, fold_predictions)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1} >>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  # Plotar matriz de confusão utilizando ConfusionMatrixDisplay\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=best_nri_svc.classes_)\n",
        "  disp.plot(cmap = 'Blues', xticks_rotation = 90, colorbar = False)   # Greys, Purples, Blues, Greens, BuGn, GnBu\n",
        "  disp.ax_.set_title(f'CM-fold {i+1}\\n (Accuracy: {accuracy_fold:.4f}, Precision: {precision_fold:.4f}, Recall: {recall_fold:.4f}, F1-score: {f1_fold:.4f})',\n",
        "                      fontsize=10)\n",
        "  disp.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "  disp.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "  plt.yticks(style='italic')\n",
        "  plt.xticks(style='italic')\n",
        "  disp.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "  disp.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "\n",
        "  # Salvando matriz de confusão\n",
        "  print(f'Salvando matriz de confusão para o folder {i+1}...')\n",
        "  plt.savefig(f'./Output_patches/CM/{i+1}_{model_name}', dpi=800, bbox_inches='tight')\n",
        "  print(f'Matriz de confusão para o folder {i+1} salva com sucesso!')\n",
        "  plt.show()\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri_svc, 'best_nri_svc')\n",
        "save_model_joblib(best_nri_svc, 'best_nri_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "PEDh6e_C-1Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2KfHP-f72IX"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVeeDNRl72IX"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri_svc = best_nri_svc.predict_proba(X_test_nri)\n",
        "prob_nri_svc = pd.DataFrame(prob_nri_svc, columns = best_nri_svc.classes_)\n",
        "class_value = prob_nri_svc.idxmax(axis=1)\n",
        "prob_value = prob_nri_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri_svc = pd.concat([y_test, prob_nri_svc], axis = 1)\n",
        "prob_nri_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zhs7Vg4T72IX"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri_svc = prob_nri_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri_svc = soma_prob_nri_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri_svc = prob_nri_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri_svc = pd.DataFrame({'Id': class_nri_svc.index,\n",
        "                          'Probabilidade': soma_prob_nri_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri_svc.values,\n",
        "                          'Classe_Observada': class_obs_nri_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri_svc = resultado_nri_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri_svc['Classe_Predita'] = resultado_nri_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3RgnhfAM72IX"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri_svc['Classe_Observada'], resultado_nri_svc['Classe_Predita']), target_names = best_nri_svc.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxzNQAwg72IX"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "\n",
        "cm_nri_svc = confusion_matrix(resultado_nri_svc['Classe_Observada'], resultado_nri_svc['Classe_Predita'])\n",
        "disp_nri_svc = ConfusionMatrixDisplay(confusion_matrix = cm_nri_svc, display_labels= best_nri_svc.classes_)\n",
        "disp_nri_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri_svc', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vIACcJESvc3"
      },
      "source": [
        "#### **Modelo C9**: Usando features LBP (Todos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador SVC\n",
        "# ================================================================================\n",
        "\n",
        "rs_unri_svc = pickle.load(open(\"./Output/LBP/Models/SVC/rs_unri_svc.pickle\", \"rb\"))\n",
        "best_unri_svc = rs_unri_svc.best_estimator_\n",
        "best_unri_svc.get_params()"
      ],
      "metadata": {
        "id": "BS6k1m_oALLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Código adaptadao para extrair matrizes de confusão por fold'''\n",
        "\n",
        "model_name = 'best_unri_svc'\n",
        "\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "with joblib.parallel_backend('multiprocessing'):\n",
        "  for i, (train_index, test_index) in enumerate(cv.split(X_train_unri, y_train['Class'], groups= z_train)):\n",
        "    print(f'Criando fold {i+1} >>>')\n",
        "    print('='*70)\n",
        "\n",
        "    print(f'Conjunto de treino antes divisão: {X_train_unri.shape}')\n",
        "    print(f'Conjunto de validação antes divisão: {X_train_unri.shape}')\n",
        "\n",
        "    # Separando fold de treino e validação\n",
        "    x_train_fold, x_test_fold = X_train_unri.iloc[train_index], X_train_unri.iloc[test_index]\n",
        "    y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "    z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "    z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "    w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "    w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "    print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "    print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "    print('='*70)\n",
        "    print(f'Treinando fold {i+1}>>>')\n",
        "\n",
        "    # Ajuste do modelo para cada fold\n",
        "    best_unri_svc.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "    print('='*70)\n",
        "    print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "    # Colete previsões para este fold\n",
        "    fold_predictions = best_unri_svc.predict_proba(x_test_fold)\n",
        "\n",
        "    # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "    fold_predictions = pd.DataFrame(fold_predictions, columns=best_unri_svc.classes_)\n",
        "    fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "    # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "    fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "    # Obtain the observed class for each group(w_test_fold)\n",
        "    fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "    # Obtendo métricas por fold\n",
        "    accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "    f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "    recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "    precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "    cm = confusion_matrix(fold_obs, fold_predictions)\n",
        "\n",
        "    print('='*70)\n",
        "    print(f'Listando métricas para o fold {i+1} >>>')\n",
        "    # Listando métricas\n",
        "    accuracy_scores.append(accuracy_fold)\n",
        "    f1_scores.append(f1_fold)\n",
        "    recall_scores.append(recall_fold)\n",
        "    precision_scores.append(precision_fold)\n",
        "\n",
        "    # Plotar matriz de confusão utilizando ConfusionMatrixDisplay\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=best_unri_svc.classes_)\n",
        "    disp.plot(cmap = 'Blues', xticks_rotation = 90, colorbar = False)   # Greys, Purples, Blues, Greens, BuGn, GnBu\n",
        "    disp.ax_.set_title(f'CM-fold {i+1}\\n (Accuracy: {accuracy_fold:.4f}, Precision: {precision_fold:.4f}, Recall: {recall_fold:.4f}, F1-score: {f1_fold:.4f})',\n",
        "                        fontsize=10)\n",
        "    disp.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "    disp.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "    plt.yticks(style='italic')\n",
        "    plt.xticks(style='italic')\n",
        "    disp.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "    disp.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "\n",
        "    # Salvando matriz de confusão\n",
        "    print(f'Salvando matriz de confusão para o folder {i+1}...')\n",
        "    plt.savefig(f'./Output_patches/LBP/CM/{i+1}_{model_name}', dpi=800, bbox_inches='tight')\n",
        "    print(f'Matriz de confusão para o folder {i+1} salva com sucesso!')\n",
        "    plt.show()\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri_svc, 'best_unri_svc')\n",
        "save_model_joblib(best_nri_svc, 'best_unri_svc')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "CAeSC0CxALLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5gfO9tqq72IY"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "178u11Ys72IY"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_unri_svc = best_unri_svc.predict_proba(X_test_unri)\n",
        "prob_unri_svc = pd.DataFrame(prob_unri_svc, columns = best_unri_svc.classes_)\n",
        "class_value = prob_unri_svc.idxmax(axis=1)\n",
        "prob_value = prob_unri_svc.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_unri_svc = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_unri_svc = pd.concat([y_test, prob_unri_svc], axis = 1)\n",
        "prob_unri_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agP82Ykd72IY"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_unri_svc = prob_unri_svc.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_unri_svc = soma_prob_unri_svc.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_unri_svc = prob_unri_svc.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_unri_svc = pd.DataFrame({'Id': class_unri_svc.index,\n",
        "                          'Probabilidade': soma_prob_unri_svc.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_unri_svc.values,\n",
        "                          'Classe_Observada': class_obs_unri_svc.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_unri_svc = resultado_unri_svc[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_unri_svc['Classe_Predita'] = resultado_unri_svc['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_unri_svc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jTET_cwd72IY"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n= 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_unri_svc['Classe_Observada'], resultado_unri_svc['Classe_Predita']), target_names = best_unri_svc.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNl0M-qv72IY"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "\n",
        "cm_unri_svc = confusion_matrix(resultado_unri_svc['Classe_Observada'], resultado_unri_svc['Classe_Predita'])\n",
        "disp_unri_svc = ConfusionMatrixDisplay(confusion_matrix = cm_unri_svc, display_labels= best_unri_svc.classes_)\n",
        "disp_unri_svc.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_unri_svc.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_unri_svc.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_unri_svc.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_unri_svc.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_unri_svc', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO63SbJJ5kl4"
      },
      "source": [
        "### **3.4 - Artificial Neural Network - ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWIMQP1UlBVU"
      },
      "source": [
        "#### **Modelo C1**: Usando features LBP Uniforme (P = 8, R = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_u81_ann = pickle.load(open(\"./Output/Models_LBP/rs_u81_ann.pickle\", \"rb\"))\n",
        "best_u81_ann = rs_u81_ann.best_estimator_"
      ],
      "metadata": {
        "id": "f1gubnKrCCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u81, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u81.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u81.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u81.iloc[train_index], X_train_u81.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u81_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u81_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u81_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u81_ann, 'best_u81_ann')\n",
        "save_model_joblib(best_u81_ann, 'best_u81_ann')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "A5qvjYx5CCjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA2rQkbT72IZ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hH5gLWGf72IZ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u81_ann = best_u81_ann.predict_proba(X_test_u81)\n",
        "prob_u81_ann = pd.DataFrame(prob_u81_ann, columns = best_u81_ann.classes_)\n",
        "class_value = prob_u81_ann.idxmax(axis=1)\n",
        "prob_value = prob_u81_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u81_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u81_ann = pd.concat([y_test, prob_u81_ann], axis = 1)\n",
        "prob_u81_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lg6SM-i772IZ"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u81_ann = prob_u81_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u81_ann = soma_prob_u81_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u81_ann = prob_u81_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u81_ann = pd.DataFrame({'Id': class_u81_ann.index,\n",
        "                          'Probabilidade': soma_prob_u81_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u81_ann.values,\n",
        "                          'Classe_Observada': class_obs_u81_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u81_ann = resultado_u81_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u81_ann['Classe_Predita'] = resultado_u81_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u81_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96GXAO-J72Ia"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação (Conjunto de teste)\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u81_ann['Classe_Observada'], resultado_u81_ann['Classe_Predita'], target_names= best_u81_ann.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0igEzmn72Ia"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u81_ann = confusion_matrix(resultado_u81_ann['Classe_Observada'], resultado_u81_ann['Classe_Predita'])\n",
        "disp_u81_ann = ConfusionMatrixDisplay(confusion_matrix = cm_u81_ann, display_labels = best_u81_ann.classes_)\n",
        "disp_u81_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u81_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u81_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u81_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u81_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_u81_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm-CRiES2Uni"
      },
      "source": [
        "#### **Modelo C2**: Usando features LBP Uniforme (P = 16, R = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_u162_ann = pickle.load(open(\"./Output/Models_LBP/rs_u162_ann.pickle\", \"rb\"))\n",
        "best_u162_ann = rs_u162_ann.best_estimator_"
      ],
      "metadata": {
        "id": "-mclVyoGFmh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u162, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u162.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u162.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u162.iloc[train_index], X_train_u162.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u162_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u162_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u162_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u162_ann, 'best_u162_ann')\n",
        "save_model_joblib(best_u162_ann, 'best_u162_ann')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "AOSWyEMyFmiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QOuaA4t72Ia"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kj59ctjk72Ia"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u162_ann = best_u162_ann.predict_proba(X_test_u162)\n",
        "prob_u162_ann = pd.DataFrame(prob_u162_ann, columns = best_u162_ann.classes_)\n",
        "class_value = prob_u162_ann.idxmax(axis=1)\n",
        "prob_value = prob_u162_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u162_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u162_ann = pd.concat([y_test, prob_u162_ann], axis = 1)\n",
        "prob_u162_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDSTzTO672Ia"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u162_ann = prob_u162_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u162_ann = soma_prob_u162_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u162_ann = prob_u162_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u162_ann = pd.DataFrame({'Id': class_u162_ann.index,\n",
        "                          'Probabilidade': soma_prob_u162_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u162_ann.values,\n",
        "                          'Classe_Observada': class_obs_u162_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u162_ann = resultado_u162_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u162_ann['Classe_Predita'] = resultado_u162_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u162_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9PKHsws_72Ib"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u162_ann['Classe_Observada'], resultado_u162_ann['Classe_Predita'], target_names= best_u162_ann.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-x_QbdY72Ib"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - conjunto de teste (n = 566)\n",
        "# ================================================================================\n",
        "cm_u162_ann = confusion_matrix(resultado_u162_ann['Classe_Observada'], resultado_u162_ann['Classe_Predita'])\n",
        "disp_u162_ann = ConfusionMatrixDisplay(confusion_matrix = cm_u162_ann, display_labels = best_u162_ann.classes_)\n",
        "disp_u162_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u162_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u162_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u162_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u162_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_u162_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtogThs0JhCz"
      },
      "source": [
        "#### **Modelo C3**: Usando features LBP Uniforme (P = 24, R = 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_u243_ann = pickle.load(open(\"./Output/Models_LBP/rs_u243_ann.pickle\", \"rb\"))\n",
        "best_u243_ann = rs_u243_ann.best_estimator_"
      ],
      "metadata": {
        "id": "Zj3-LiSyGsZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u243, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u243.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u243.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u243.iloc[train_index], X_train_u243.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u243_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u243_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u243_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u243_ann, 'best_u243_ann')\n",
        "save_model_joblib(best_u243_ann, 'best_u243_ann')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "uILiZ3gkGsZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVyY8tcF72Ib"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uK5UIVD72Ib"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u243_ann = best_u243_ann.predict_proba(X_test_u243)\n",
        "prob_u243_ann = pd.DataFrame(prob_u243_ann, columns = best_u243_ann.classes_)\n",
        "class_value = prob_u243_ann.idxmax(axis=1)\n",
        "prob_value = prob_u243_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u243_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u243_ann = pd.concat([y_test, prob_u243_ann], axis = 1)\n",
        "prob_u243_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3L5MNA9e72Ib"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u243_ann = prob_u243_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u243_ann = soma_prob_u243_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u243_ann = prob_u243_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u243_ann = pd.DataFrame({'Id': class_u243_ann.index,\n",
        "                          'Probabilidade': soma_prob_u243_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u243_ann.values,\n",
        "                          'Classe_Observada': class_obs_u243_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u243_ann = resultado_u243_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u243_ann['Classe_Predita'] = resultado_u243_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u243_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBvzle-H72Ic"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n= 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u243_ann['Classe_Observada'], resultado_u243_ann['Classe_Predita'], target_names= best_u243_ann.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVrqycP-72Ic"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u243_ann = confusion_matrix(resultado_u243_ann['Classe_Observada'], resultado_u243_ann['Classe_Predita'])\n",
        "disp_u243_ann = ConfusionMatrixDisplay(confusion_matrix = cm_u243_ann, display_labels = best_u243_ann.classes_)\n",
        "disp_u243_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u243_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u243_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u243_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u243_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_u243_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPi7Ugqliifc"
      },
      "source": [
        "#### **Modelo C4**: Usando features LBP Uniforme (Todos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_uni_ann = pickle.load(open(\"./Output/Models_LBP/rs_uni_ann.pickle\", \"rb\"))\n",
        "best_uni_ann = rs_uni_ann.best_estimator_"
      ],
      "metadata": {
        "id": "h4jE0K5kHts5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u.iloc[train_index], X_train_u.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_uni_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_uni_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_uni_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_uni_ann, 'best_uni_ann')\n",
        "save_model_joblib(best_uni_ann, 'best_uni_ann')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "mPHgKF5jHttD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wrrFCMY472Ic"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roDGQu0t72Ic"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_uni_ann = best_uni_ann.predict_proba(X_test_u)\n",
        "prob_uni_ann = pd.DataFrame(prob_uni_ann, columns = best_uni_ann.classes_)\n",
        "class_value = prob_uni_ann.idxmax(axis=1)\n",
        "prob_value = prob_uni_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_uni_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_uni_ann = pd.concat([y_test, prob_uni_ann], axis = 1)\n",
        "prob_uni_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2DbPqpC72Ic"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_uni_ann = prob_uni_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_uni_ann = soma_prob_uni_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_uni_ann = prob_uni_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_uni_ann = pd.DataFrame({'Id': class_uni_ann.index,\n",
        "                          'Probabilidade': soma_prob_uni_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_uni_ann.values,\n",
        "                          'Classe_Observada': class_obs_uni_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_uni_ann = resultado_uni_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_uni_ann['Classe_Predita'] = resultado_uni_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_uni_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZ9fEHPA72Ic"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_uni_ann['Classe_Observada'], resultado_uni_ann['Classe_Predita'], target_names= best_uni_ann.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrFTSkD-72Ic"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_uni_ann = confusion_matrix(resultado_uni_ann['Classe_Observada'], resultado_uni_ann['Classe_Predita'])\n",
        "disp_uni_ann = ConfusionMatrixDisplay(confusion_matrix = cm_uni_ann, display_labels = best_uni_ann.classes_)\n",
        "disp_uni_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_uni_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_uni_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_uni_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_uni_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_uni_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVwTghifxM_c"
      },
      "source": [
        "#### **Modelo M5**: Usando features LBP Uniforme Não Invariante (P = 8, R = 1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri81_ann = pickle.load(open(\"./Output/Models_LBP/rs_nri81_ann.pickle\", \"rb\"))\n",
        "best_nri81_ann = rs_nri81_ann.best_estimator_"
      ],
      "metadata": {
        "id": "8XBJSsuHIzqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri81, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri81.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri81.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri81.iloc[train_index], X_train_nri81.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri81_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri81_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri81_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri81_ann, 'best_nri81_ann')\n",
        "save_model_joblib(best_nri81_ann, 'best_nri81_ann')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "D_SLkZxJIzqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZ_KFj2v72Id"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hUaPMXPU72Ie"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri81_ann = best_nri81_ann.predict_proba(X_test_nri81)\n",
        "prob_nri81_ann = pd.DataFrame(prob_nri81_ann, columns = best_nri81_ann.classes_)\n",
        "class_value = prob_nri81_ann.idxmax(axis=1)\n",
        "prob_value = prob_nri81_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri81_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri81_ann = pd.concat([y_test, prob_nri81_ann], axis = 1)\n",
        "prob_nri81_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Utd---m772Ie"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri81_ann = prob_nri81_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri81_ann = soma_prob_nri81_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri81_ann = prob_nri81_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri81_ann = pd.DataFrame({'Id': class_nri81_ann.index,\n",
        "                          'Probabilidade': soma_prob_nri81_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri81_ann.values,\n",
        "                          'Classe_Observada': class_obs_nri81_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri81_ann = resultado_nri81_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri81_ann['Classe_Predita'] = resultado_nri81_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri81_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fcjleLL72Ie"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n= 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri81_ann['Classe_Observada'], resultado_nri81_ann['Classe_Predita'], target_names= best_nri81_ann.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVES695v72Ie"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri81_ann = confusion_matrix(resultado_nri81_ann['Classe_Observada'], resultado_nri81_ann['Classe_Predita'])\n",
        "disp_nri81_ann = ConfusionMatrixDisplay(confusion_matrix = cm_nri81_ann, display_labels = best_nri81_ann.classes_)\n",
        "disp_nri81_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri81_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri81_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri81_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri81_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri81_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFWCYX0S0v3r"
      },
      "source": [
        "#### **Modelo M6**: Usando features LBP Uniforme Não Invariante (P = 16, R = 2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri162_ann = pickle.load(open(\"./Output/LBP/Models/ANN/rs_nri162_ann.pickle\", \"rb\"))\n",
        "best_nri162_ann = rs_nri162_ann.best_estimator_\n",
        "best_nri162_ann.get_params()"
      ],
      "metadata": {
        "id": "uBi1ldBoJ-qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri162, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri162.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri162.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri162.iloc[train_index], X_train_nri162.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri162_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri162_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri162_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri162_ann, 'best_nri162_ann')\n",
        "save_model_joblib(best_nri162_ann, 'best_nri162_ann')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "9Ms6Am0CJ-qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFyrFDAM72If"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpMFr2Ux72If"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "#best_nri162_ann = pickle.load(open(\"./Output_patches/LBP/Models/ANN/best_nri162_ann.pickle\", \"rb\"))\n",
        "prob_nri162_ann = best_nri162_ann.predict_proba(X_test_nri162)\n",
        "prob_nri162_ann = pd.DataFrame(prob_nri162_ann, columns = best_nri162_ann.classes_)\n",
        "class_value = prob_nri162_ann.idxmax(axis=1)\n",
        "prob_value = prob_nri162_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri162_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri162_ann = pd.concat([y_test, prob_nri162_ann], axis = 1)\n",
        "prob_nri162_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyEOps-772If"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri162_ann = prob_nri162_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri162_ann = soma_prob_nri162_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri162_ann = prob_nri162_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri162_ann = pd.DataFrame({'Id': class_nri162_ann.index,\n",
        "                          'Probabilidade': soma_prob_nri162_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri162_ann.values,\n",
        "                          'Classe_Observada': class_obs_nri162_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri162_ann = resultado_nri162_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri162_ann['Classe_Predita'] = resultado_nri162_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri162_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nisGdNA72If"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri162_ann['Classe_Observada'], resultado_nri162_ann['Classe_Predita']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2Zry_Te72If"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri162_ann = confusion_matrix(resultado_nri162_ann['Classe_Observada'], resultado_nri162_ann['Classe_Predita'], labels = classes)\n",
        "disp_nri162_ann = ConfusionMatrixDisplay(confusion_matrix = cm_nri162_ann, display_labels= classes)\n",
        "disp_nri162_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri162_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri162_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri162_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri162_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CNN/CM/SVC/cm_nri162_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWuR4i-X5D3v"
      },
      "source": [
        "#### **Modelo C7**: Usando features LBP Uniforme Não Invariante (P = 24, R = 3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri243_ann = pickle.load(open(\"./Output/Models_LBP/rs_nri243_ann.pickle\", \"rb\"))\n",
        "best_nri243_ann = rs_nri243_ann.best_estimator_"
      ],
      "metadata": {
        "id": "TQqa-QTaLDRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri243, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri243.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri243.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri243.iloc[train_index], X_train_nri243.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri243_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri243_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri243_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri243_ann, 'best_nri243_ann')\n",
        "save_model_joblib(best_nri243_ann, 'best_nri243_ann')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "gK600KcJLDRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PR2-QXMX72If"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M59OC3P72If"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri243_ann = best_nri243_ann.predict_proba(X_test_nri243)\n",
        "prob_nri243_ann = pd.DataFrame(prob_nri243_ann, columns = best_nri243_ann.classes_)\n",
        "class_value = prob_nri243_ann.idxmax(axis=1)\n",
        "prob_value = prob_nri243_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri243_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri243_ann = pd.concat([y_test, prob_nri243_ann], axis = 1)\n",
        "prob_nri243_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k30cOJwI72Ig"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri243_ann = prob_nri243_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri243_ann = soma_prob_nri243_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri243_ann = prob_nri243_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri243_ann = pd.DataFrame({'Id': class_nri243_ann.index,\n",
        "                          'Probabilidade': soma_prob_nri243_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri243_ann.values,\n",
        "                          'Classe_Observada': class_obs_nri243_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri243_ann = resultado_nri243_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri243_ann['Classe_Predita'] = resultado_nri243_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri243_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18kBomrb72Ig"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n= 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri243_ann['Classe_Observada'], resultado_nri243_ann['Classe_Predita'], target_names= best_nri243_ann.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hQg6DVc72Ig"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri243_ann = confusion_matrix(resultado_nri243_ann['Classe_Observada'], resultado_nri243_ann['Classe_Predita'])\n",
        "disp_nri243_ann = ConfusionMatrixDisplay(confusion_matrix = cm_nri243_ann, display_labels = best_nri243_ann.classes_)\n",
        "disp_nri243_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri243_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri243_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri243_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri243_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri243_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP4r8lRk75F2"
      },
      "source": [
        "#### **Modelo C8**: Usando features LBP Uniforme Não Invariante (Todos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri_ann = pickle.load(open(\"./Output/LBP/Models/ANN/rs_nri_ann.pickle\", \"rb\"))\n",
        "best_nri_ann = rs_nri_ann.best_estimator_\n",
        "model_name = 'best_nri_ann'\n",
        "best_nri_ann.get_params()"
      ],
      "metadata": {
        "id": "7EgRLebUBdfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes divisão: {X_train_nri.shape}')\n",
        "  print(f'Conjunto de validação antes divisão: {X_train_nri.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri.iloc[train_index], X_train_nri.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1}>>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "  cm = confusion_matrix(fold_obs, fold_predictions)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1} >>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  # Plotar matriz de confusão utilizando ConfusionMatrixDisplay\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=best_nri_ann.classes_)\n",
        "  disp.plot(cmap = 'Blues', xticks_rotation = 90, colorbar = False)   # Greys, Purples, Blues, Greens, BuGn, GnBu\n",
        "  disp.ax_.set_title(f'CM-fold {i+1}\\n (Accuracy: {accuracy_fold:.4f}, Precision: {precision_fold:.4f}, Recall: {recall_fold:.4f}, F1-score: {f1_fold:.4f})',\n",
        "                      fontsize=10)\n",
        "  disp.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "  disp.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "  plt.yticks(style='italic')\n",
        "  plt.xticks(style='italic')\n",
        "  disp.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "  disp.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "  plt.show()\n",
        "\n",
        "  # Salvando matriz de confusão\n",
        "  print(f'Salvando matriz de confusão para o folder {i+1}...')\n",
        "  plt.savefig(f'./Output_patches/CM/{i+1}_{model_name}', dpi=800, bbox_inches='tight')\n",
        "  print(f'Matriz de confusão para o folder {i+1} salva com sucesso!')\n",
        "  plt.show()\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri_ann, 'best_nri_ann')\n",
        "save_model_joblib(best_nri_ann, 'best_nri_ann')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "-PjkwumUbU33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN_rjHlsMDIe"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4yHnJjOJSdm"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri_ann = best_nri_ann.predict_proba(X_test_nri)\n",
        "prob_nri_ann = pd.DataFrame(prob_nri_ann, columns = best_nri_ann.classes_)\n",
        "class_value = prob_nri_ann.idxmax(axis=1)\n",
        "prob_value = prob_nri_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri_ann = pd.concat([y_test, prob_nri_ann], axis = 1)\n",
        "prob_nri_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow_s74CCJSdn"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri_ann = prob_nri_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri_ann = soma_prob_nri_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri_ann = prob_nri_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri_ann = pd.DataFrame({'Id': class_nri_ann.index,\n",
        "                          'Probabilidade': soma_prob_nri_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri_ann.values,\n",
        "                          'Classe_Observada': class_obs_nri_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri_ann = resultado_nri_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri_ann['Classe_Predita'] = resultado_nri_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fdig906-RIpI"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n= 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri_ann['Classe_Observada'], resultado_nri_ann['Classe_Predita'], target_names= best_nri_ann.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz_kEXs7RIpI"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri_ann = confusion_matrix(resultado_nri_ann['Classe_Observada'], resultado_nri_ann['Classe_Predita'])\n",
        "disp_nri_ann = ConfusionMatrixDisplay(confusion_matrix = cm_nri_ann, display_labels = best_nri_ann.classes_)\n",
        "disp_nri_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pe_KiGfDTBxO"
      },
      "source": [
        "#### **Modelo C9**: Usando features LBP (Todos)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador ANN\n",
        "# ================================================================================\n",
        "\n",
        "rs_unri_ann = pickle.load(open('./Output/Models_LBP/rs_unri_ann.pickle', \"rb\"))\n",
        "best_unri_ann = rs_unri_ann.best_estimator_\n",
        "model_name = 'best_unri_ann'"
      ],
      "metadata": {
        "id": "KoSihprzsvRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WBsNVa272Ii"
      },
      "outputs": [],
      "source": [
        "'''O código foi alterado para incluir a obtenção das matrizes de confusão por fold'''\n",
        "\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_unri, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes divisão: {X_train_unri.shape}')\n",
        "  print(f'Conjunto de validação antes divisão: {X_train_unri.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_unri.iloc[train_index], X_train_unri.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1}>>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_unri_ann.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_unri_ann.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_unri_ann.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1} >>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  # Plotar matriz de confusão utilizando ConfusionMatrixDisplay\n",
        "  cm = confusion_matrix(fold_obs, fold_predictions)\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=best_unri_ann.classes_)\n",
        "  disp.plot(cmap = 'Blues', xticks_rotation = 90, colorbar = False)   # Greys, Purples, Blues, Greens, BuGn, GnBu\n",
        "  disp.ax_.set_title(f'CM-fold {i+1}\\n (Accuracy: {accuracy_fold:.4f}, Precision: {precision_fold:.4f}, Recall: {recall_fold:.4f}, F1-score: {f1_fold:.4f})',\n",
        "                      fontsize=10)\n",
        "  disp.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "  disp.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "  plt.yticks(style='italic')\n",
        "  plt.xticks(style='italic')\n",
        "  disp.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "  disp.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "\n",
        "  # Salvando matriz de confusão\n",
        "  print(f'Salvando matriz de confusão para o folder {i+1}...')\n",
        "  plt.savefig(f'./Output_patches/CM/{i+1}_{model_name}', dpi=800, bbox_inches='tight')\n",
        "  print(f'Matriz de confusão para o folder {i+1} salva com sucesso!')\n",
        "  plt.show()\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_unri_ann, 'best_unri_ann')\n",
        "save_model_joblib(best_unri_ann, 'best_unri_ann')\n",
        "\n",
        "print('MODELO SALVO!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ompOpk9072Ii"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_ZVsaQG72Ii"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_unri_ann = best_unri_ann.predict_proba(X_test_unri)\n",
        "prob_unri_ann = pd.DataFrame(prob_unri_ann, columns = best_unri_ann.classes_)\n",
        "class_value = prob_unri_ann.idxmax(axis=1)\n",
        "prob_value = prob_unri_ann.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_unri_ann = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_unri_ann = pd.concat([y_test, prob_unri_ann], axis = 1)\n",
        "prob_unri_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHNP45P072Ii"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_unri_ann = prob_unri_ann.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_unri_ann = soma_prob_unri_ann.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_unri_ann = prob_unri_ann.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_unri_ann = pd.DataFrame({'Id': class_unri_ann.index,\n",
        "                          'Probabilidade': soma_prob_unri_ann.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_unri_ann.values,\n",
        "                          'Classe_Observada': class_obs_unri_ann.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_unri_ann = resultado_unri_ann[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_unri_ann['Classe_Predita'] = resultado_unri_ann['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_unri_ann"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5FhYHK372Ii"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_unri_ann['Classe_Observada'], resultado_unri_ann['Classe_Predita'], target_names= best_unri_ann.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGrXVPsB72Ii"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_unri_ann = confusion_matrix(resultado_unri_ann['Classe_Observada'], resultado_unri_ann['Classe_Predita'])\n",
        "disp_unri_ann = ConfusionMatrixDisplay(confusion_matrix = cm_unri_ann, display_labels = best_unri_ann.classes_)\n",
        "disp_unri_ann.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_unri_ann.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_unri_ann.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_unri_ann.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_unri_ann.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig(f'./Output_patches/CM/cm_unri_ann', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSp0dKT672Ij"
      },
      "source": [
        "### **3.5 - Random Forest - RF**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaCJSf4y72Ij"
      },
      "source": [
        "#### **Modelo C1**: Usando features LBP Uniforme (P = 8, R = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x88BiA_R72Ij"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "rs_u81_rf = pickle.load(open('./Output/Models_LBP/rs_u81_rf.pickle', \"rb\"))\n",
        "best_u81_rf = rs_u81_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u81, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u81.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u81.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u81.iloc[train_index], X_train_u81.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u81_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u81_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u81_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u81_rf, 'best_u81_rf')\n",
        "save_model_joblib(best_u81_rf, 'best_u81_rf')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "7s2pqrz-OWLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFj8wqcJ72Ij"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w1RAsinl72Ij"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u81_rf = best_u81_rf.predict_proba(X_test_u81)\n",
        "prob_u81_rf = pd.DataFrame(prob_u81_rf, columns = best_u81_rf.classes_)\n",
        "class_value = prob_u81_rf.idxmax(axis=1)\n",
        "prob_value = prob_u81_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u81_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u81_rf = pd.concat([y_test, prob_u81_rf], axis = 1)\n",
        "prob_u81_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daIV_AZO72Ij"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u81_rf = prob_u81_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u81_rf = soma_prob_u81_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u81_rf = prob_u81_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u81_rf = pd.DataFrame({'Id': class_u81_rf.index,\n",
        "                          'Probabilidade': soma_prob_u81_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u81_rf.values,\n",
        "                          'Classe_Observada': class_obs_u81_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u81_rf = resultado_u81_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u81_rf['Classe_Predita'] = resultado_u81_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u81_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPYEHSyx72Ij"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u81_rf['Classe_Observada'], resultado_u81_rf['Classe_Predita'], target_names= best_u81_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJP7kEoS72Ij"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u81_rf = confusion_matrix(resultado_u81_rf['Classe_Observada'], resultado_u81_rf['Classe_Predita'])\n",
        "disp_u81_rf = ConfusionMatrixDisplay(confusion_matrix = cm_u81_rf, display_labels = best_u81_rf.classes_)\n",
        "disp_u81_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u81_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u81_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u81_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u81_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_u81_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dH7LV3K72Ik"
      },
      "source": [
        "#### **Modelo C2**: Usando features LBP Uniforme (P = 16, R = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCFuGicUPZXO"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "rs_u162_rf = pickle.load(open('./Output/Models_LBP/rs_u162_rf.pickle', \"rb\"))\n",
        "best_u162_rf = rs_u162_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u162, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u162.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u162.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u162.iloc[train_index], X_train_u162.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u162_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u162_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u162_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u162_rf, 'best_u162_rf')\n",
        "save_model_joblib(best_u162_rf, 'best_u162_rf')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "-ptIwzHlPZXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVBJrko272Ik"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL10k-7k72Ik"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u162_rf = best_u162_rf.predict_proba(X_test_u162)\n",
        "prob_u162_rf = pd.DataFrame(prob_u162_rf, columns = best_u162_rf.classes_)\n",
        "class_value = prob_u162_rf.idxmax(axis=1)\n",
        "prob_value = prob_u162_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u162_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u162_rf = pd.concat([y_test, prob_u162_rf], axis = 1)\n",
        "prob_u162_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeedOfDs72Il"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u162_rf = prob_u162_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u162_rf = soma_prob_u162_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u162_rf = prob_u162_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u162_rf = pd.DataFrame({'Id': class_u162_rf.index,\n",
        "                          'Probabilidade': soma_prob_u162_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u162_rf.values,\n",
        "                          'Classe_Observada': class_obs_u162_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u162_rf = resultado_u162_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u162_rf['Classe_Predita'] = resultado_u162_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u162_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHpA5N2E72Il"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u162_rf['Classe_Observada'], resultado_u162_rf['Classe_Predita'], target_names= best_u162_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-HmAOIv72Il"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u162_rf = confusion_matrix(resultado_u162_rf['Classe_Observada'], resultado_u162_rf['Classe_Predita'])\n",
        "disp_u162_rf = ConfusionMatrixDisplay(confusion_matrix = cm_u162_rf, display_labels = best_u162_rf.classes_)\n",
        "disp_u162_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u162_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u162_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u162_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u162_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_u162_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHEpQv1J72Il"
      },
      "source": [
        "#### **Modelo C3**: Usando features LBP Uniforme (P = 24, R = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iPHj6BC6RIW8"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "rs_u243_rf = pickle.load(open('./Output/Models_LBP/rs_u243_rf.pickle', \"rb\"))\n",
        "best_u243_rf = rs_u243_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u243, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u243.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u243.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u243.iloc[train_index], X_train_u243.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u243_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u243_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u243_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u243_rf, 'best_u243_rf')\n",
        "save_model_joblib(best_u243_rf, 'best_u243_rf')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "YKAo2AJ0RIW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHFxIFYy72Il"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0yGrtyA72Il"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u243_rf = best_u243_rf.predict_proba(X_test_u243)\n",
        "prob_u243_rf = pd.DataFrame(prob_u243_rf, columns = best_u243_rf.classes_)\n",
        "class_value = prob_u243_rf.idxmax(axis=1)\n",
        "prob_value = prob_u243_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u243_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u243_rf = pd.concat([y_test, prob_u243_rf], axis = 1)\n",
        "prob_u243_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW43XcSF72Il"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u243_rf = prob_u243_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u243_rf = soma_prob_u243_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u243_rf = prob_u243_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u243_rf = pd.DataFrame({'Id': class_u243_rf.index,\n",
        "                          'Probabilidade': soma_prob_u243_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u243_rf.values,\n",
        "                          'Classe_Observada': class_obs_u243_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u243_rf = resultado_u243_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u243_rf['Classe_Predita'] = resultado_u243_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u243_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqWMwSji72Il"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u243_rf['Classe_Observada'], resultado_u243_rf['Classe_Predita'], target_names= best_u243_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUTt65cj72Il"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u243_rf = confusion_matrix(resultado_u243_rf['Classe_Observada'], resultado_u243_rf['Classe_Predita'])\n",
        "disp_u243_rf = ConfusionMatrixDisplay(confusion_matrix = cm_u243_rf, display_labels = best_u243_rf.classes_)\n",
        "disp_u243_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u243_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u243_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u243_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u243_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_u243_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wP3PqUCt72Im"
      },
      "source": [
        "#### **Modelo C4**: Usando features LBP Uniforme (Todos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bIVvUR7Sdn3"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "rs_uni_rf = pickle.load(open('./Output/Models_LBP/rs_uni_rf.pickle', \"rb\"))\n",
        "best_uni_rf = rs_uni_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u.iloc[train_index], X_train_u.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_uni_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_uni_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_uni_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_uni_rf, 'best_uni_rf')\n",
        "save_model_joblib(best_uni_rf, 'best_uni_rf')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "tuGS06YJSdn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjsl45Mg72Im"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHJUngEs72Io"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_uni_rf = best_uni_rf.predict_proba(X_test_u)\n",
        "prob_uni_rf = pd.DataFrame(prob_uni_rf, columns = best_uni_rf.classes_)\n",
        "class_value = prob_uni_rf.idxmax(axis=1)\n",
        "prob_value = prob_uni_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_uni_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_uni_rf = pd.concat([y_test, prob_uni_rf], axis = 1)\n",
        "prob_uni_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2KU1iI972Ip"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_uni_rf = prob_uni_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_uni_rf = soma_prob_uni_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_uni_rf = prob_uni_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_uni_rf = pd.DataFrame({'Id': class_uni_rf.index,\n",
        "                          'Probabilidade': soma_prob_uni_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_uni_rf.values,\n",
        "                          'Classe_Observada': class_obs_uni_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_uni_rf = resultado_uni_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_uni_rf['Classe_Predita'] = resultado_uni_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_uni_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SptzZeV172Ip"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_uni_rf['Classe_Observada'], resultado_uni_rf['Classe_Predita'], target_names= best_uni_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MXB39mU72Ip"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_uni_rf = confusion_matrix(resultado_uni_rf['Classe_Observada'], resultado_uni_rf['Classe_Predita'])\n",
        "disp_uni_rf = ConfusionMatrixDisplay(confusion_matrix = cm_uni_rf, display_labels = best_uni_rf.classes_)\n",
        "disp_uni_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_uni_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_uni_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_uni_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_uni_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_uni_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C5**: Usando features LBP Uniforme Não Invariante (P = 8, R = 1)"
      ],
      "metadata": {
        "id": "IKjOipJ59uJE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DstZCq5NdQn2"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "rs_nri81_rf = pickle.load(open('./Output/Models_LBP/rs_nri81_rf.pickle', \"rb\"))\n",
        "best_nri81_rf = rs_nri81_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri81, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri81.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri81.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri81.iloc[train_index], X_train_nri81.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri81_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri81_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri81_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri81_rf, 'best_nri81_rf')\n",
        "save_model_joblib(best_nri81_rf, 'best_nri81_rf')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "tufjVR9hdQn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_XjjsJ6_X2R"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dURB9WZi_X2S"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri81_rf = best_nri81_rf.predict_proba(X_test_nri81)\n",
        "prob_nri81_rf = pd.DataFrame(prob_uni_rf, columns = best_nri81_rf.classes_)\n",
        "class_value = prob_nri81_rf.idxmax(axis=1)\n",
        "prob_value = prob_nri81_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri81_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri81_rf = pd.concat([y_test, prob_nri81_rf], axis = 1)\n",
        "prob_nri81_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3sW6vdb_X2S"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri81_rf = prob_nri81_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri81_rf = soma_prob_nri81_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri81_rf= prob_nri81_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri81_rf = pd.DataFrame({'Id': class_nri81_rf.index,\n",
        "                          'Probabilidade': soma_prob_nri81_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri81_rf.values,\n",
        "                          'Classe_Observada': class_obs_nri81_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri81_rf = resultado_nri81_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri81_rf['Classe_Predita'] = resultado_nri81_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri81_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l0SUvfYn_X2T"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri81_rf['Classe_Observada'], resultado_nri81_rf['Classe_Predita'], target_names= best_nri81_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRT_cZic_X2T"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri81_rf = confusion_matrix(resultado_nri81_rf['Classe_Observada'], resultado_nri81_rf['Classe_Predita'])\n",
        "disp_nri81_rf = ConfusionMatrixDisplay(confusion_matrix = cm_nri81_rf, display_labels = best_nri81_rf.classes_)\n",
        "disp_nri81_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri81_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri81_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri81_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri81_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri81_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C6**: Usando features LBP Uniforme Não Invariante (P = 16, R = 2)"
      ],
      "metadata": {
        "id": "DDRDM9DECtd2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SCLNzdBeUy6"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "rs_nri162_rf = pickle.load(open('./Output/Models_LBP/rs_nri162_rf.pickle', \"rb\"))\n",
        "best_nri162_rf = rs_nri162_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri162, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri162.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri162.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri162.iloc[train_index], X_train_nri162.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri162_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri162_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri162_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri162_rf, 'best_nri162_rf')\n",
        "save_model_joblib(best_nri162_rf, 'best_nri162_rf')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "RUnXOF-geUy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEPaCoHICtd3"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fp9DvaW9Ctd3"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri162_rf = best_nri162_rf.predict_proba(X_test_nri162)\n",
        "prob_nri162_rf = pd.DataFrame(prob_nri162_rf, columns = best_nri162_rf.classes_)\n",
        "class_value = prob_nri162_rf.idxmax(axis=1)\n",
        "prob_value = prob_nri162_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri162_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri162_rf = pd.concat([y_test, prob_nri162_rf], axis = 1)\n",
        "prob_nri162_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwRVl2-tCtd3"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri162_rf = prob_nri162_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri162_rf = soma_prob_nri162_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri162_rf= prob_nri162_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri162_rf = pd.DataFrame({'Id': class_nri162_rf.index,\n",
        "                          'Probabilidade': soma_prob_nri162_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri162_rf.values,\n",
        "                          'Classe_Observada': class_obs_nri162_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri162_rf = resultado_nri162_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri162_rf['Classe_Predita'] = resultado_nri162_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri162_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU7tc6qICtd3"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri162_rf['Classe_Observada'], resultado_nri162_rf['Classe_Predita'], target_names= best_nri162_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvldbYQYCtd3"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri162_rf = confusion_matrix(resultado_nri162_rf['Classe_Observada'], resultado_nri162_rf['Classe_Predita'])\n",
        "disp_nri162_rf = ConfusionMatrixDisplay(confusion_matrix = cm_nri162_rf, display_labels = best_nri162_rf.classes_)\n",
        "disp_nri162_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri162_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri162_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri162_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri162_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri162_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C7**: Usando features LBP Uniforme Não Invariante (P = 24, R = 3)"
      ],
      "metadata": {
        "id": "D3nS6UZREywf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW-F3PQ1fYkL"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "rs_nri243_rf = pickle.load(open('./Output/Models_LBP/rs_nri243_rf.pickle', \"rb\"))\n",
        "best_nri243_rf = rs_nri243_rf.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri243, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri243.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri243.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri243.iloc[train_index], X_train_nri243.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri243_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri243_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri243_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri243_rf, 'best_nri243_rf')\n",
        "save_model_joblib(best_nri243_rf, 'best_nri243_rf')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "LX0HeMZWfYkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLYQTT0wEywm"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FEgF-V3YEywm"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri243_rf = best_nri243_rf.predict_proba(X_test_nri243)\n",
        "prob_nri243_rf = pd.DataFrame(prob_nri243_rf, columns = best_nri243_rf.classes_)\n",
        "class_value = prob_nri243_rf.idxmax(axis=1)\n",
        "prob_value = prob_nri243_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri243_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri243_rf = pd.concat([y_test, prob_nri243_rf], axis = 1)\n",
        "prob_nri243_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WhujNRxPEywn"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri243_rf = prob_nri243_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri243_rf = soma_prob_nri243_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri243_rf= prob_nri243_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri243_rf = pd.DataFrame({'Id': class_nri243_rf.index,\n",
        "                          'Probabilidade': soma_prob_nri243_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri243_rf.values,\n",
        "                          'Classe_Observada': class_obs_nri243_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri243_rf = resultado_nri243_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri243_rf['Classe_Predita'] = resultado_nri243_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri243_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzzYCqX5Eywn"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri243_rf['Classe_Observada'], resultado_nri243_rf['Classe_Predita'], target_names= best_nri243_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPMdy9NNEywn"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri243_rf = confusion_matrix(resultado_nri243_rf['Classe_Observada'], resultado_nri243_rf['Classe_Predita'])\n",
        "disp_nri243_rf = ConfusionMatrixDisplay(confusion_matrix = cm_nri243_rf, display_labels = best_nri243_rf.classes_)\n",
        "disp_nri243_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri243_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri243_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri243_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri243_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri243_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C8**: Usando features LBP Uniforme Não Invariante (Todos)"
      ],
      "metadata": {
        "id": "XApFkRUrKBAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri_rf = pickle.load(open('./Output/Models_LBP/rs_nri_rf.pickle', \"rb\"))\n",
        "best_nri_rf = rs_nri_rf.best_estimator_\n",
        "model_name = 'best_nri_rf'"
      ],
      "metadata": {
        "id": "dhhIzVUTgXi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oud0XUfTgw8k"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes divisão: {X_train_nri.shape}')\n",
        "  print(f'Conjunto de validação antes divisão: {X_train_nri.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri.iloc[train_index], X_train_nri.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1}>>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "  cm = confusion_matrix(fold_obs, fold_predictions)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1} >>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  # Plotar matriz de confusão utilizando ConfusionMatrixDisplay\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=best_nri_rf.classes_)\n",
        "  disp.plot(cmap = 'Blues', xticks_rotation = 90, colorbar = False)   # Greys, Purples, Blues, Greens, BuGn, GnBu\n",
        "  disp.ax_.set_title(f'CM-fold {i+1}\\n (Accuracy: {accuracy_fold:.4f}, Precision: {precision_fold:.4f}, Recall: {recall_fold:.4f}, F1-score: {f1_fold:.4f})',\n",
        "                      fontsize=10)\n",
        "  disp.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "  disp.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "  plt.yticks(style='italic')\n",
        "  plt.xticks(style='italic')\n",
        "  disp.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "  disp.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "  plt.show()\n",
        "\n",
        "  # Salvando matriz de confusão\n",
        "  print(f'Salvando matriz de confusão para o folder {i+1}...')\n",
        "  plt.savefig(f'./Output_patches/CM/{i+1}_{model_name}', dpi=800, bbox_inches='tight')\n",
        "  print(f'Matriz de confusão para o folder {i+1} salva com sucesso!')\n",
        "  plt.show()\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri_rf, 'best_nri_rf')\n",
        "save_model_joblib(best_nri_rf, 'best_nri_rf')\n",
        "\n",
        "print('MODELO SALVO!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJllHINLKJqD"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg4sokd_KJqE"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri_rf = best_nri_rf.predict_proba(X_test_nri)\n",
        "prob_nri_rf = pd.DataFrame(prob_nri_rf, columns = best_nri_rf.classes_)\n",
        "class_value = prob_nri_rf.idxmax(axis=1)\n",
        "prob_value = prob_nri_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri_rf = pd.concat([y_test, prob_nri_rf], axis = 1)\n",
        "prob_nri_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeBoxh23KJqE"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri_rf = prob_nri_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri_rf = soma_prob_nri_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri_rf= prob_nri_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri_rf = pd.DataFrame({'Id': class_nri_rf.index,\n",
        "                          'Probabilidade': soma_prob_nri_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri_rf.values,\n",
        "                          'Classe_Observada': class_obs_nri_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri_rf = resultado_nri_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri_rf['Classe_Predita'] = resultado_nri_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-8NOdsqKJqE"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri_rf['Classe_Observada'], resultado_nri_rf['Classe_Predita'], target_names= best_nri_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXdr2nTGKJqE"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri_rf = confusion_matrix(resultado_nri_rf['Classe_Observada'], resultado_nri_rf['Classe_Predita'])\n",
        "disp_nri_rf = ConfusionMatrixDisplay(confusion_matrix = cm_nri_rf, display_labels = best_nri_rf.classes_)\n",
        "disp_nri_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_nri_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C9**: Usando features LBP (Todos)"
      ],
      "metadata": {
        "id": "Ux0nF9hkMLdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "\n",
        "rs_unri_rf = pickle.load(open('./Output/Models_LBP/rs_unri_rf.pickle', \"rb\"))\n",
        "best_unri_rf = rs_unri_rf.best_estimator_\n",
        "model_name = 'best_unri_rf'"
      ],
      "metadata": {
        "id": "MZt89EQTiF6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dE78SPBXiF62"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_unri, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes divisão: {X_train_unri.shape}')\n",
        "  print(f'Conjunto de validação antes divisão: {X_train_unri.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_unri.iloc[train_index], X_train_unri.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1}>>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_unri_rf.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_unri_rf.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_unri_rf.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "  cm = confusion_matrix(fold_obs, fold_predictions)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1} >>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  # Plotar matriz de confusão utilizando ConfusionMatrixDisplay\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=best_unri_rf.classes_)\n",
        "  disp.plot(cmap = 'Blues', xticks_rotation = 90, colorbar = False)   # Greys, Purples, Blues, Greens, BuGn, GnBu\n",
        "  disp.ax_.set_title(f'CM-fold {i+1}\\n (Accuracy: {accuracy_fold:.4f}, Precision: {precision_fold:.4f}, Recall: {recall_fold:.4f}, F1-score: {f1_fold:.4f})',\n",
        "                      fontsize=10)\n",
        "  disp.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "  disp.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "  plt.yticks(style='italic')\n",
        "  plt.xticks(style='italic')\n",
        "  disp.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "  disp.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "  plt.show()\n",
        "\n",
        "  # Salvando matriz de confusão\n",
        "  print(f'Salvando matriz de confusão para o folder {i+1}...')\n",
        "  plt.savefig(f'./Output_patches/CM/{i+1}_{model_name}', dpi=800, bbox_inches='tight')\n",
        "  print(f'Matriz de confusão para o folder {i+1} salva com sucesso!')\n",
        "  plt.show()\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_unri_rf, 'best_unri_rf')\n",
        "save_model_joblib(best_unri_rf, 'best_unri_rf')\n",
        "\n",
        "print('MODELO SALVO!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHnrvl8cL-fj"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMOjJURgL-fj"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_unri_rf = best_unri_rf.predict_proba(X_test_unri)\n",
        "prob_unri_rf = pd.DataFrame(prob_unri_rf, columns = best_unri_rf.classes_)\n",
        "class_value = prob_unri_rf.idxmax(axis=1)\n",
        "prob_value = prob_unri_rf.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_unri_rf = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_unri_rf = pd.concat([y_test, prob_unri_rf], axis = 1)\n",
        "prob_unri_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iF467GHvL-fk"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_unri_rf = prob_unri_rf.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_unri_rf = soma_prob_unri_rf.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_unri_rf= prob_unri_rf.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_unri_rf = pd.DataFrame({'Id': class_unri_rf.index,\n",
        "                          'Probabilidade': soma_prob_unri_rf.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_unri_rf.values,\n",
        "                          'Classe_Observada': class_obs_unri_rf.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_unri_rf = resultado_unri_rf[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_unri_rf['Classe_Predita'] = resultado_unri_rf['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_unri_rf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOHlojABL-fk"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_unri_rf['Classe_Observada'], resultado_unri_rf['Classe_Predita'], target_names= best_unri_rf.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rIGLZZUL-fk"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_unri_rf = confusion_matrix(resultado_unri_rf['Classe_Observada'], resultado_unri_rf['Classe_Predita'])\n",
        "disp_unri_rf = ConfusionMatrixDisplay(confusion_matrix = cm_unri_rf, display_labels = best_unri_rf.classes_)\n",
        "disp_unri_rf.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_unri_rf.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_unri_rf.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_unri_rf.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_unri_rf.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/CM/cm_unri_rf', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.6 - Linear Discriminat Analisys - LDA**"
      ],
      "metadata": {
        "id": "FzjXOyRd1jhG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIGwZhnA16h3"
      },
      "source": [
        "#### **Modelo M1**: Usando features LBP Uniforme (P = 8, R = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8PZNVnb16iG"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador LDA\n",
        "# ================================================================================\n",
        "rs_u81_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_u81_lda.pickle', \"rb\"))\n",
        "best_u81_lda = rs_u81_lda.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u81, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u81.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u81.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u81.iloc[train_index], X_train_u81.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u81_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u81_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u81_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u81_lda, 'best_u81_lda')\n",
        "save_model_joblib(best_u81_lda, 'best_u81_lda')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "f-tgkJe016iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMDMHhYJ16iS"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9nSCWf316iS"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u81_lda = best_u81_lda.predict_proba(X_test_u81)\n",
        "prob_u81_lda = pd.DataFrame(prob_u81_lda, columns = best_u81_lda.classes_)\n",
        "class_value = prob_u81_lda.idxmax(axis=1)\n",
        "prob_value = prob_u81_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u81_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u81_lda = pd.concat([y_test, prob_u81_lda], axis = 1)\n",
        "prob_u81_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_hCugLvI16iT"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u81_lda = prob_u81_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u81_lda = soma_prob_u81_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u81_lda = prob_u81_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u81_lda = pd.DataFrame({'Id': class_u81_lda.index,\n",
        "                          'Probabilidade': soma_prob_u81_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u81_lda.values,\n",
        "                          'Classe_Observada': class_obs_u81_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u81_lda = resultado_u81_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u81_lda['Classe_Predita'] = resultado_u81_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u81_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nxh9eAo316iT"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u81_lda['Classe_Observada'], resultado_u81_lda['Classe_Predita'], target_names= best_u81_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IguFpqxt16iT"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u81_lda = confusion_matrix(resultado_u81_lda['Classe_Observada'], resultado_u81_lda['Classe_Predita'])\n",
        "disp_u81_lda = ConfusionMatrixDisplay(confusion_matrix = cm_u81_lda, display_labels = best_u81_lda.classes_)\n",
        "disp_u81_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u81_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u81_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u81_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u81_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "plt.show()\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_u81_lda', dpi=800, bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UltsMaNh16iU"
      },
      "source": [
        "#### **Modelo C2**: Usando features LBP Uniforme (P = 16, R = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mt5AyjHh16iU"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador LDA\n",
        "# ================================================================================\n",
        "rs_u162_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_u162_lda.pickle', \"rb\"))\n",
        "best_u162_lda = rs_u162_lda.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u162, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u162.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u162.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u162.iloc[train_index], X_train_u162.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u162_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u162_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u162_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u162_lda, 'best_u162_lda')\n",
        "save_model_joblib(best_u162_lda, 'best_u162_lda')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "SVbFo4VT16iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaDC_DnJ16iV"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-7gw3DX16iW"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u162_lda = best_u162_lda.predict_proba(X_test_u162)\n",
        "prob_u162_lda = pd.DataFrame(prob_u162_lda, columns = best_u162_lda.classes_)\n",
        "class_value = prob_u162_lda.idxmax(axis=1)\n",
        "prob_value = prob_u162_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u162_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u162_lda = pd.concat([y_test, prob_u162_lda], axis = 1)\n",
        "prob_u162_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thFzMJ2B16iX"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u162_lda = prob_u162_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u162_lda = soma_prob_u162_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u162_lda = prob_u162_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u162_lda = pd.DataFrame({'Id': class_u162_lda.index,\n",
        "                          'Probabilidade': soma_prob_u162_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u162_lda.values,\n",
        "                          'Classe_Observada': class_obs_u162_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u162_lda = resultado_u162_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u162_lda['Classe_Predita'] = resultado_u162_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u162_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSZHwzua16iY"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u162_lda['Classe_Observada'], resultado_u162_lda['Classe_Predita'], target_names= best_u162_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2egDstJj16iY"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u162_lda = confusion_matrix(resultado_u162_lda['Classe_Observada'], resultado_u162_lda['Classe_Predita'])\n",
        "disp_u162_lda = ConfusionMatrixDisplay(confusion_matrix = cm_u162_lda, display_labels = best_u162_lda.classes_)\n",
        "disp_u162_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u162_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u162_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u162_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u162_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_u162_lda', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cj-le1q16ia"
      },
      "source": [
        "#### **Modelo C3**: Usando features LBP Uniforme (P = 24, R = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mh0yd7bd16ib"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador LDA\n",
        "# ================================================================================\n",
        "rs_u243_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_u243_lda.pickle', \"rb\"))\n",
        "best_u243_lda = rs_u243_lda.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u243, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u243.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u243.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u243.iloc[train_index], X_train_u243.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_u243_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_u243_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_u243_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_u243_lda, 'best_u243_lda')\n",
        "save_model_joblib(best_u243_lda, 'best_u243_lda')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "r_MMdNYu16ib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IUUZvFS16ie"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HJw7ij816if"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_u243_lda = best_u243_lda.predict_proba(X_test_u243)\n",
        "prob_u243_lda = pd.DataFrame(prob_u243_lda, columns = best_u243_lda.classes_)\n",
        "class_value = prob_u243_lda.idxmax(axis=1)\n",
        "prob_value = prob_u243_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_u243_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_u243_lda = pd.concat([y_test, prob_u243_lda], axis = 1)\n",
        "prob_u243_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6P4PP0l16if"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n = 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_u243_lda = prob_u243_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_u243_lda = soma_prob_u243_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_u243_lda = prob_u243_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_u243_lda = pd.DataFrame({'Id': class_u243_lda.index,\n",
        "                          'Probabilidade': soma_prob_u243_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_u243_lda.values,\n",
        "                          'Classe_Observada': class_obs_u243_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_u243_lda = resultado_u243_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_u243_lda['Classe_Predita'] = resultado_u243_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_u243_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cezy-y8716if"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_u243_lda['Classe_Observada'], resultado_u243_lda['Classe_Predita'], target_names= best_u243_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_hzkrHb16ig"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_u243_lda = confusion_matrix(resultado_u243_lda['Classe_Observada'], resultado_u243_lda['Classe_Predita'])\n",
        "disp_u243_lda = ConfusionMatrixDisplay(confusion_matrix = cm_u243_lda, display_labels = best_u243_lda.classes_)\n",
        "disp_u243_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_u243_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u243_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_u243_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_u243_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_u243_lda', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UPs_Dwe16ig"
      },
      "source": [
        "#### **Modelo C4**: Usando features LBP Uniforme (Todos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svcuG4vZ16ih"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador LDA\n",
        "# ================================================================================\n",
        "rs_uni_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_uni_lda.pickle', \"rb\"))\n",
        "best_uni_lda = rs_uni_lda.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_u, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_u.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_u.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_u.iloc[train_index], X_train_u.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_uni_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_uni_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_uni_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_uni_lda, 'best_uni_lda')\n",
        "save_model_joblib(best_uni_lda, 'best_uni_lda')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "jY8eYyjv16ih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIqIKL9H16ih"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DH6fKu7316ih"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_uni_lda = best_uni_lda.predict_proba(X_test_u)\n",
        "prob_uni_lda = pd.DataFrame(prob_uni_lda, columns = best_uni_lda.classes_)\n",
        "class_value = prob_uni_lda.idxmax(axis=1)\n",
        "prob_value = prob_uni_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_uni_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_uni_lda = pd.concat([y_test, prob_uni_lda], axis = 1)\n",
        "prob_uni_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH54DpIO16ii"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_uni_lda = prob_uni_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_uni_lda = soma_prob_uni_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_uni_lda = prob_uni_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_uni_lda = pd.DataFrame({'Id': class_uni_lda.index,\n",
        "                          'Probabilidade': soma_prob_uni_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_uni_lda.values,\n",
        "                          'Classe_Observada': class_obs_uni_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_uni_lda = resultado_uni_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_uni_lda['Classe_Predita'] = resultado_uni_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_uni_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aUepAfUc16ii"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_uni_lda['Classe_Observada'], resultado_uni_lda['Classe_Predita'], target_names= best_uni_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWpwhHD316ii"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_uni_lda = confusion_matrix(resultado_uni_lda['Classe_Observada'], resultado_uni_lda['Classe_Predita'])\n",
        "disp_uni_lda = ConfusionMatrixDisplay(confusion_matrix = cm_uni_lda, display_labels = best_uni_lda.classes_)\n",
        "disp_uni_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_uni_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_uni_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_uni_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_uni_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_uni_lda', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C5**: Usando features LBP Uniforme Não Invariante (P = 8, R = 1)"
      ],
      "metadata": {
        "id": "g9FvILTL16ij"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K70ASUAc16ij"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador LDA\n",
        "# ================================================================================\n",
        "rs_nri81_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_nri81_lda.pickle', \"rb\"))\n",
        "best_nri81_lda = rs_nri81_lda.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri81, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri81.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri81.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri81.iloc[train_index], X_train_nri81.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri81_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri81_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri81_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri81_lda, 'best_nri81_lda')\n",
        "save_model_joblib(best_nri81_lda, 'best_nri81_lda')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "IAjEJdv416ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vevXw0Aj16ik"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejQ6rPtG16il"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri81_lda = best_nri81_lda.predict_proba(X_test_nri81)\n",
        "prob_nri81_lda = pd.DataFrame(prob_uni_lda, columns = best_nri81_lda.classes_)\n",
        "class_value = prob_nri81_lda.idxmax(axis=1)\n",
        "prob_value = prob_nri81_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri81_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri81_lda = pd.concat([y_test, prob_nri81_lda], axis = 1)\n",
        "prob_nri81_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LlDC-AO16il"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri81_lda = prob_nri81_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri81_lda = soma_prob_nri81_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri81_lda= prob_nri81_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri81_lda = pd.DataFrame({'Id': class_nri81_lda.index,\n",
        "                          'Probabilidade': soma_prob_nri81_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri81_lda.values,\n",
        "                          'Classe_Observada': class_obs_nri81_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri81_lda = resultado_nri81_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri81_lda['Classe_Predita'] = resultado_nri81_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri81_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsAVFvJR16il"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri81_lda['Classe_Observada'], resultado_nri81_lda['Classe_Predita'], target_names= best_nri81_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXbXD_0Y16il"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri81_lda = confusion_matrix(resultado_nri81_lda['Classe_Observada'], resultado_nri81_lda['Classe_Predita'])\n",
        "disp_nri81_lda = ConfusionMatrixDisplay(confusion_matrix = cm_nri81_lda, display_labels = best_nri81_lda.classes_)\n",
        "disp_nri81_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri81_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri81_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri81_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri81_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_nri81_lda', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C6**: Usando features LBP Uniforme Não Invariante (P = 16, R = 2)"
      ],
      "metadata": {
        "id": "GK_TYmPX16im"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-AGxv5j16im"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador LDA\n",
        "# ================================================================================\n",
        "rs_nri162_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_nri162_lda.pickle', \"rb\"))\n",
        "best_nri162_lda = rs_nri162_lda.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri162, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri162.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri162.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri162.iloc[train_index], X_train_nri162.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri162_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri162_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri162_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri162_lda, 'best_nri162_lda')\n",
        "save_model_joblib(best_nri162_lda, 'best_nri162_lda')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "IFrm3Hz216im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSye6NrA16in"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGi3DIpy16in"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri162_lda = best_nri162_lda.predict_proba(X_test_nri162)\n",
        "prob_nri162_lda = pd.DataFrame(prob_nri162_lda, columns = best_nri162_lda.classes_)\n",
        "class_value = prob_nri162_lda.idxmax(axis=1)\n",
        "prob_value = prob_nri162_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri162_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri162_lda = pd.concat([y_test, prob_nri162_lda], axis = 1)\n",
        "prob_nri162_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxo4ZHlV16in"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri162_lda = prob_nri162_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri162_lda = soma_prob_nri162_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri162_lda= prob_nri162_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri162_lda = pd.DataFrame({'Id': class_nri162_lda.index,\n",
        "                          'Probabilidade': soma_prob_nri162_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri162_lda.values,\n",
        "                          'Classe_Observada': class_obs_nri162_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri162_lda = resultado_nri162_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri162_lda['Classe_Predita'] = resultado_nri162_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri162_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-ypHtmP16io"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri162_lda['Classe_Observada'], resultado_nri162_lda['Classe_Predita'], target_names= best_nri162_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wnQBB_r16io"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri162_lda = confusion_matrix(resultado_nri162_lda['Classe_Observada'], resultado_nri162_lda['Classe_Predita'])\n",
        "disp_nri162_lda = ConfusionMatrixDisplay(confusion_matrix = cm_nri162_lda, display_labels = best_nri162_lda.classes_)\n",
        "disp_nri162_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri162_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri162_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri162_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri162_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_nri162_lda', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C7**: Usando features LBP Uniforme Não Invariante (P = 24, R = 3)"
      ],
      "metadata": {
        "id": "uQqXASvh16io"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hrFpc8s16ip"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador RF\n",
        "# ================================================================================\n",
        "rs_nri243_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_nri243_lda.pickle', \"rb\"))\n",
        "best_nri243_lda = rs_nri243_lda.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri243, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes da divisão: {X_train_nri243.shape}')\n",
        "  print(f'Conjunto de validação antes da divisão: {X_train_nri243.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri243.iloc[train_index], X_train_nri243.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1} >>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri243_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri243_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri243_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1}>>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  print(f'Fold {i+1} finalizado!!!')\n",
        "  print('*'*70)\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri243_lda, 'best_nri243_lda')\n",
        "save_model_joblib(best_nri243_lda, 'best_nri243_lda')\n",
        "\n",
        "print('MODELO SALVO!')"
      ],
      "metadata": {
        "id": "zdrTOlq916ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GVwjex116iq"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWaES5xm16iq"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri243_lda = best_nri243_lda.predict_proba(X_test_nri243)\n",
        "prob_nri243_lda = pd.DataFrame(prob_nri243_lda, columns = best_nri243_lda.classes_)\n",
        "class_value = prob_nri243_lda.idxmax(axis=1)\n",
        "prob_value = prob_nri243_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri243_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri243_lda = pd.concat([y_test, prob_nri243_lda], axis = 1)\n",
        "prob_nri243_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bFq7UyR16iq"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri243_lda = prob_nri243_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri243_lda = soma_prob_nri243_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri243_lda= prob_nri243_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri243_lda = pd.DataFrame({'Id': class_nri243_lda.index,\n",
        "                          'Probabilidade': soma_prob_nri243_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri243_lda.values,\n",
        "                          'Classe_Observada': class_obs_nri243_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri243_lda = resultado_nri243_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri243_lda['Classe_Predita'] = resultado_nri243_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri243_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UlSzdvG16ir"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri243_lda['Classe_Observada'], resultado_nri243_lda['Classe_Predita'], target_names= best_nri243_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AwAb_TB16ir"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri243_lda = confusion_matrix(resultado_nri243_lda['Classe_Observada'], resultado_nri243_lda['Classe_Predita'])\n",
        "disp_nri243_lda = ConfusionMatrixDisplay(confusion_matrix = cm_nri243_lda, display_labels = best_nri243_lda.classes_)\n",
        "disp_nri243_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri243_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri243_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri243_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri243_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_nri243_lda', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C8**: Usando features LBP Uniforme Não Invariante (Todos)"
      ],
      "metadata": {
        "id": "KvBXzS1g16iu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador LDA\n",
        "# ================================================================================\n",
        "\n",
        "rs_nri_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_nri_lda.pickle', \"rb\"))\n",
        "best_nri_lda = rs_nri_lda.best_estimator_\n",
        "model_name = 'best_nri_lda'"
      ],
      "metadata": {
        "id": "yLO-Kv5216i1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4rI6GiD16i1"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_nri, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes divisão: {X_train_nri.shape}')\n",
        "  print(f'Conjunto de validação antes divisão: {X_train_nri.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_nri.iloc[train_index], X_train_nri.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1}>>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_nri_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_nri_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_nri_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "  cm = confusion_matrix(fold_obs, fold_predictions)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1} >>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  # Plotar matriz de confusão utilizando ConfusionMatrixDisplay\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=best_nri_lda.classes_)\n",
        "  disp.plot(cmap = 'Blues', xticks_rotation = 90, colorbar = False)   # Greys, Purples, Blues, Greens, BuGn, GnBu\n",
        "  disp.ax_.set_title(f'CM-fold {i+1}\\n (Accuracy: {accuracy_fold:.4f}, Precision: {precision_fold:.4f}, Recall: {recall_fold:.4f}, F1-score: {f1_fold:.4f})',\n",
        "                      fontsize=10)\n",
        "  disp.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "  disp.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "  plt.yticks(style='italic')\n",
        "  plt.xticks(style='italic')\n",
        "  disp.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "  disp.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "\n",
        "  # Salvando matriz de confusão\n",
        "  print(f'Salvando matriz de confusão para o folder {i+1}...')\n",
        "  plt.savefig(f'./Output_patches/LBP/CM/{i+1}_{model_name}', dpi=800, bbox_inches='tight')\n",
        "  print(f'Matriz de confusão para o folder {i+1} salva com sucesso!')\n",
        "  plt.show()\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_nri_lda, 'best_nri_lda')\n",
        "save_model_joblib(best_nri_lda, 'best_nri_lda')\n",
        "\n",
        "print('MODELO SALVO!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2M1fYua16i2"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kB0TaqJ16i2"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_nri_lda = best_nri_lda.predict_proba(X_test_nri)\n",
        "prob_nri_lda = pd.DataFrame(prob_nri_lda, columns = best_nri_lda.classes_)\n",
        "class_value = prob_nri_lda.idxmax(axis=1)\n",
        "prob_value = prob_nri_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_nri_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_nri_lda = pd.concat([y_test, prob_nri_lda], axis = 1)\n",
        "prob_nri_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reJLKg4F16i2"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_nri_lda = prob_nri_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_nri_lda = soma_prob_nri_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_nri_lda= prob_nri_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_nri_lda = pd.DataFrame({'Id': class_nri_lda.index,\n",
        "                          'Probabilidade': soma_prob_nri_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_nri_lda.values,\n",
        "                          'Classe_Observada': class_obs_nri_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_nri_lda = resultado_nri_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_nri_lda['Classe_Predita'] = resultado_nri_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_nri_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjQTnbRj16i2"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_nri_lda['Classe_Observada'], resultado_nri_lda['Classe_Predita'], target_names= best_nri_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oznrt7u016i3"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_nri_lda = confusion_matrix(resultado_nri_lda['Classe_Observada'], resultado_nri_lda['Classe_Predita'])\n",
        "disp_nri_lda = ConfusionMatrixDisplay(confusion_matrix = cm_nri_lda, display_labels = best_nri_lda.classes_)\n",
        "disp_nri_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_nri_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_nri_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_nri_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_nri_lda', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Modelo C9**: Usando features LBP (Todos)"
      ],
      "metadata": {
        "id": "qbTnP92H16i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# Definições do estimador LDA\n",
        "# ================================================================================\n",
        "\n",
        "rs_unri_lda = pickle.load(open('./Output/LBP/Models/LDA/rs_unri_lda.pickle', \"rb\"))\n",
        "best_unri_lda = rs_unri_lda.best_estimator_\n",
        "model_name = 'best_unri_lda'"
      ],
      "metadata": {
        "id": "f4PJGsGD16i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qie7mo-o16i4"
      },
      "outputs": [],
      "source": [
        "\n",
        "accuracy_scores = []\n",
        "f1_scores = []\n",
        "recall_scores = []\n",
        "precision_scores = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(cv.split(X_train_unri, y_train['Class'], groups= z_train)):\n",
        "  print(f'Criando fold {i+1} >>>')\n",
        "  print('='*70)\n",
        "\n",
        "  print(f'Conjunto de treino antes divisão: {X_train_unri.shape}')\n",
        "  print(f'Conjunto de validação antes divisão: {X_train_unri.shape}')\n",
        "\n",
        "  # Separando fold de treino e validação\n",
        "  x_train_fold, x_test_fold = X_train_unri.iloc[train_index], X_train_unri.iloc[test_index]\n",
        "  y_train_fold, y_test_fold = y_train['Class'].iloc[train_index], y_train['Class'].iloc[test_index]\n",
        "  z_train_fold = [name.split('_')[0] for name in z_train.iloc[train_index]]\n",
        "  z_test_fold = [name.split('_')[0] for name in z_train.iloc[test_index]]\n",
        "  w_train_fold = [name.split('_')[1] for name in z_train.iloc[train_index]]\n",
        "  w_test_fold = [name.split('_')[1] for name in z_train.iloc[test_index]]\n",
        "\n",
        "  print(f'Conjunto de treino após divisão: {x_train_fold.shape}')\n",
        "  print(f'Conjunto de validação após divisão: {x_test_fold.shape}')\n",
        "  print('='*70)\n",
        "  print(f'Treinando fold {i+1}>>>')\n",
        "\n",
        "  # Ajuste do modelo para cada fold\n",
        "  best_unri_lda.fit(x_train_fold, y_train_fold)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Fazendo previsões para o fold {i+1}>>>')\n",
        "  # Colete previsões para este fold\n",
        "  fold_predictions = best_unri_lda.predict_proba(x_test_fold)\n",
        "\n",
        "  # Soma das probabilidades das classes dentro de cada grupo(w_test_fold)\n",
        "  fold_predictions = pd.DataFrame(fold_predictions, columns=best_unri_lda.classes_)\n",
        "  fold_predictions = fold_predictions.groupby(w_test_fold).sum()\n",
        "\n",
        "  # Encontrando classe com maior probabilidade para cada grupo(w_test_fold)\n",
        "  fold_predictions = fold_predictions.idxmax(axis=1)\n",
        "\n",
        "  # Obtain the observed class for each group(w_test_fold)\n",
        "  fold_obs = y_test_fold.groupby(w_test_fold).first()\n",
        "\n",
        "  # Obtendo métricas por fold\n",
        "  accuracy_fold = accuracy_score(fold_obs, fold_predictions)\n",
        "  f1_fold = f1_score(fold_obs, fold_predictions, average='weighted')\n",
        "  recall_fold = recall_score(fold_obs, fold_predictions, average='weighted')\n",
        "  precision_fold = precision_score(fold_obs, fold_predictions, average='weighted')\n",
        "  cm = confusion_matrix(fold_obs, fold_predictions)\n",
        "\n",
        "  print('='*70)\n",
        "  print(f'Listando métricas para o fold {i+1} >>>')\n",
        "  # Listando métricas\n",
        "  accuracy_scores.append(accuracy_fold)\n",
        "  f1_scores.append(f1_fold)\n",
        "  recall_scores.append(recall_fold)\n",
        "  precision_scores.append(precision_fold)\n",
        "\n",
        "  # Plotar matriz de confusão utilizando ConfusionMatrixDisplay\n",
        "  disp = ConfusionMatrixDisplay(confusion_matrix= cm, display_labels=best_unri_lda.classes_)\n",
        "  disp.plot(cmap = 'Blues', xticks_rotation = 90, colorbar = False)   # Greys, Purples, Blues, Greens, BuGn, GnBu\n",
        "  disp.ax_.set_title(f'CM-fold {i+1}\\n (Accuracy: {accuracy_fold:.4f}, Precision: {precision_fold:.4f}, Recall: {recall_fold:.4f}, F1-score: {f1_fold:.4f})',\n",
        "                      fontsize=10)\n",
        "  disp.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "  disp.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "  plt.yticks(style='italic')\n",
        "  plt.xticks(style='italic')\n",
        "  disp.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "  disp.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "\n",
        "  # Salvando matriz de confusão\n",
        "  print(f'Salvando matriz de confusão para o folder {i+1}...')\n",
        "  plt.savefig(f'./Output_patches/LBP/CM/{i+1}_{model_name}', dpi=800, bbox_inches='tight')\n",
        "  print(f'Matriz de confusão para o folder {i+1} salva com sucesso!')\n",
        "  plt.show()\n",
        "\n",
        "# Salvando o modelo\n",
        "print('='*70)\n",
        "print('Salvando modelo...')\n",
        "save_model_pickle(best_unri_lda, 'best_unri_lda')\n",
        "save_model_joblib(best_unri_lda, 'best_unri_lda')\n",
        "\n",
        "print('MODELO SALVO!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "viJJ96yL16i4"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Visualizando métricas por fold - Conjunto de Validação - Voto Majoritário\n",
        "#===============================================================================\n",
        "\n",
        "print('='*70)\n",
        "print(\"Métricas por fold:\")\n",
        "print('='*70)\n",
        "for i in range(len(accuracy_scores)):\n",
        "    print(f\"Fold {i+1}: Accuracy={accuracy_scores[i]:.4f}, F1={f1_scores[i]:.4f}, Recall={recall_scores[i]:.4f}, Precision={precision_scores[i]:.4f}\")\n",
        "\n",
        "# Calculando média das métricas\n",
        "mean_accuracy = np.mean(accuracy_scores)\n",
        "std_accuracy = np.std(accuracy_scores)\n",
        "min_acc = np.min(accuracy_scores)\n",
        "max_acc = np.max(accuracy_scores)\n",
        "mean_f1 = np.mean(f1_scores)\n",
        "std_f1 = np.std(f1_scores)\n",
        "min_f1 = np.min(f1_scores)\n",
        "max_f1 = np.max(f1_scores)\n",
        "mean_recall = np.mean(recall_scores)\n",
        "std_recall = np.std(recall_scores)\n",
        "min_recall = np.min(recall_scores)\n",
        "max_recall = np.max(recall_scores)\n",
        "mean_precision = np.mean(precision_scores)\n",
        "std_precision = np.std(precision_scores)\n",
        "min_precision = np.min(precision_scores)\n",
        "max_precision = np.max(precision_scores)\n",
        "\n",
        "print('='*70)\n",
        "print(\"Mean -- Standard Deviation -- Minimum Value -- Maximum Value\")\n",
        "print('='*70)\n",
        "# Visualizando média das métricas\n",
        "print(f\"Accuracy -> mean: {mean_accuracy:.4f}, std: {std_accuracy:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"F1 Score -> mean: {mean_f1:.4f}, std: {std_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
        "print(f\"Recall -> mean: {mean_recall:.4f}, std: {std_recall:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")\n",
        "print(f\"Precision -> mean: {mean_precision:.4f}, std: {std_precision:.4f}, min: {min_acc:.4f}, max: {max_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSNUQiFo16i4"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo tabela de probabilidades - 28300 patches de imagens\n",
        "#===============================================================================\n",
        "\n",
        "prob_unri_lda = best_unri_lda.predict_proba(X_test_unri)\n",
        "prob_unri_lda = pd.DataFrame(prob_unri_lda, columns = best_unri_lda.classes_)\n",
        "class_value = prob_unri_lda.idxmax(axis=1)\n",
        "prob_value = prob_unri_lda.max(axis=1)\n",
        "\n",
        "# Obtendo tabela de classes preditas e observadas\n",
        "prob_unri_lda = pd.DataFrame({'Classe_Predita': class_value, 'Probabilidade': prob_value})\n",
        "prob_unri_lda = pd.concat([y_test, prob_unri_lda], axis = 1)\n",
        "prob_unri_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2BzYNUo16i_"
      },
      "outputs": [],
      "source": [
        "#===============================================================================\n",
        "# Obtendo resultado por Voto Majoritário (n= 566)\n",
        "#===============================================================================\n",
        "\n",
        "# Agrupar os dados por 'Id' e calcular a soma das probabilidades para cada classe\n",
        "soma_prob_unri_lda = prob_unri_lda.groupby('Id').apply(lambda x: x.groupby('Classe_Predita')['Probabilidade'].sum())\n",
        "\n",
        "# Para cada grupo de 'Id', selecionar a classe com a maior soma de probabilidades\n",
        "class_unri_lda = soma_prob_unri_lda.groupby('Id').idxmax()\n",
        "\n",
        "# Obter a classe observada para cada grupo de 'Id'\n",
        "class_obs_unri_lda= prob_unri_lda.groupby('Id')['Class'].first()\n",
        "\n",
        "# Criar um DataFrame com as informações de interesse\n",
        "resultado_unri_lda = pd.DataFrame({'Id': class_unri_lda.index,\n",
        "                          'Probabilidade': soma_prob_unri_lda.groupby('Id').max(),\n",
        "                          'Classe_Predita': class_unri_lda.values,\n",
        "                          'Classe_Observada': class_obs_unri_lda.values})\n",
        "\n",
        "# Exibir o resultado\n",
        "resultado_unri_lda = resultado_unri_lda[['Probabilidade', 'Classe_Predita', 'Classe_Observada']]\n",
        "# Extrair apenas o nome da classe predita\n",
        "resultado_unri_lda['Classe_Predita'] = resultado_unri_lda['Classe_Predita'].apply(lambda x: x[1])\n",
        "resultado_unri_lda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mCQnIUB16jA"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Relatório de classificação - Conjunto de teste (n=566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "print(classification_report(resultado_unri_lda['Classe_Observada'], resultado_unri_lda['Classe_Predita'], target_names= best_unri_lda.classes_))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-dg0KP716jA"
      },
      "outputs": [],
      "source": [
        "# ================================================================================\n",
        "# Matriz de Confusão - Conjunto de Teste (n = 566) - Voto Majoritário\n",
        "# ================================================================================\n",
        "cm_unri_lda = confusion_matrix(resultado_unri_lda['Classe_Observada'], resultado_unri_lda['Classe_Predita'])\n",
        "disp_unri_lda = ConfusionMatrixDisplay(confusion_matrix = cm_unri_lda, display_labels = best_unri_lda.classes_)\n",
        "disp_unri_lda.plot(cmap = 'Blues', xticks_rotation = 90)\n",
        "disp_unri_lda.ax_.set_xlabel('Predito', fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_unri_lda.ax_.set_ylabel(\"Observado\", fontsize=10, style='normal', fontweight = 'bold')\n",
        "disp_unri_lda.ax_.xaxis.set_tick_params(labelsize=10)\n",
        "disp_unri_lda.ax_.yaxis.set_tick_params(labelsize=10)\n",
        "plt.yticks(style='italic')\n",
        "plt.xticks(style='italic')\n",
        "\n",
        "plt.savefig('./Output_patches/LBP/CM/cm_unri_lda', dpi=800, bbox_inches='tight')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "b0w1CcyDk9gQ",
        "Ub6t6EIiqvts",
        "5Fk7FiYreEvR",
        "zOTRWhRWlUWG",
        "DjsaGYjHxCvo",
        "cGQMwve86eCF",
        "5Ya7JDI5BtZu",
        "K59mwtlx1kTh",
        "nUzgOLPh-oB2",
        "0vIACcJESvc3",
        "RO63SbJJ5kl4",
        "WWIMQP1UlBVU",
        "Qm-CRiES2Uni",
        "vtogThs0JhCz",
        "cPi7Ugqliifc",
        "TVwTghifxM_c",
        "RFWCYX0S0v3r",
        "yWuR4i-X5D3v",
        "SP4r8lRk75F2",
        "pe_KiGfDTBxO",
        "wSp0dKT672Ij",
        "UaCJSf4y72Ij",
        "9dH7LV3K72Ik",
        "IHEpQv1J72Il",
        "wP3PqUCt72Im",
        "IKjOipJ59uJE",
        "DDRDM9DECtd2",
        "D3nS6UZREywf",
        "XApFkRUrKBAH",
        "Ux0nF9hkMLdt",
        "FzjXOyRd1jhG",
        "lIGwZhnA16h3",
        "UltsMaNh16iU",
        "8cj-le1q16ia",
        "2UPs_Dwe16ig",
        "g9FvILTL16ij",
        "GK_TYmPX16im",
        "uQqXASvh16io",
        "KvBXzS1g16iu",
        "qbTnP92H16i3"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}