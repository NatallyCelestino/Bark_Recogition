{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1iX60tC3ySp2B4Ab4wz-VjSpmLoBviAae","timestamp":1713212714868}],"collapsed_sections":["d1PsqyJ5MFi5"],"authorship_tag":"ABX9TyNhErAMLB19WZ8bvZaOqCB4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","source":["----\n","\n","# ü§ñ Transfer Learning - Transfer√™ncia de Aprendizado ü§ñ\n","\n","----\n","\n","A Transfer√™ncia de aprendizado √© baseada na aplica√ß√£o do conhecimento aprendido no processo de treinamento de uma Rede Neural Convolucional (CNN), de um determinado problema para outro diferente, por√©m, semelhante. Aqui utilizamos quatro redes neurais pr√©-treinadas, comuns em problemas de classifica√ß√£o de imagens: ResNet50, VGG16, InceptionV3 e MobileNetV2.\n","\n","As redes s√£o carregadas com pesos ImageNet, sendo a √∫tima camada de classifica√ß√£o removida, e uma camada de GlobalAveragepooling adicionada para formar o extrator de caracter√≠sticas das imagens. As caracter√≠sticas extra√≠das s√£o salvas em um arquivo .npz, para serem utilizadas como vetores de entrada nos algoritmos de machine learning.\n","\n","Mais detalhes sobre cada uma das redes, podem sera acessados atrav√©s do link: [Keras Applications](https://keras.io/api/applications/)"],"metadata":{"id":"ptP2xZQu__qK"}},{"cell_type":"markdown","source":["Conectando ao Google Drive"],"metadata":{"id":"nMzbustFA4ly"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"B_ezp9KJAzxN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **1- Importando Bibliotecas**"],"metadata":{"id":"P8_fIQD7A-hi"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import cv2\n","import os\n","import glob\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import keras\n","from keras.models import Sequential\n","from keras.models import load_model, save_model\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications.resnet50 import ResNet50\n","from keras.applications.vgg16 import VGG16\n","from keras.applications.inception_v3 import InceptionV3\n","from keras.applications.inception_v3 import preprocess_input\n","from keras.applications.mobilenet_v2 import MobileNetV2\n","from keras.applications.mobilenet_v2 import preprocess_input\n","from keras.applications.vgg16 import preprocess_input\n","from keras.applications.resnet50 import preprocess_input\n","from keras.layers import GlobalAveragePooling2D\n","from keras.layers import BatchNormalization\n","from keras.layers import Dropout\n","from keras.models import Model"],"metadata":{"id":"VGTdtpjQBHmw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **2- Extraindo caracter√≠sticas das imagens inteiras**"],"metadata":{"id":"vgTjdirfNk20"}},{"cell_type":"markdown","source":["## **Carregando dados**"],"metadata":{"id":"jYJDPX4b4cY3"}},{"cell_type":"code","source":["# ============================================================================================================================\n","# Carregar arquivos com caminhos e nomes das esp√©cies (Mapeia os nomes pelos c√≥digos)\n","# ============================================================================================================================\n","df = pd.read_csv('./Amazon_Bark_Split/filepath.csv')\n","labels = pd.read_csv('./Class.csv', sep = ';')\n","df['Specie'] = df['Class'].map(labels.set_index('Code')['Specie'])"],"metadata":{"id":"8nR55QUwNwf2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Separandos dados, labels e amostras\n","#------------------------------------------------------------------------------#\n","train = df.loc[df['Set'] == 'train']                                                        # Filtra linhas \"train\"\n","test = df.loc[df['Set'] == 'test']                                                          # Filtra linhas \"test\"\n","\n","# Labels\n","y_train = df.loc[df['Set'] == 'train', 'Specie']\n","y_test = df.loc[df['Set'] == 'test', 'Specie']\n","\n","# Samples\n","sample_train = df.loc[df['Set'] == 'train', 'Sample']\n","sample_test = df.loc[df['Set'] == 'test', 'Sample']"],"metadata":{"id":"OV_HqqDMO-uW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":450,"status":"ok","timestamp":1713058692083,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"},"user_tz":180},"id":"86vx1lkmHajm","outputId":"1d6e0bf4-3147-4625-f2be-5034b6bb9941"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2237 validated image filenames belonging to 16 classes.\n","Found 566 validated image filenames belonging to 16 classes.\n"]}],"source":["# ============================================================================================================================\n","# Carregar lotes de imagens - (ImageDataGenerator + flow_from_dataframe)\n","# ============================================================================================================================\n","# Pr√© processamento\n","train_gen = ImageDataGenerator()\n","test_gen = ImageDataGenerator()\n","\n","train_generator = train_gen.flow_from_dataframe(dataframe = train,\n","                                                directory = './Amazon_Bark_Split/train',\n","                                                x_col = 'filename',\n","                                                y_col = 'Specie',\n","                                                class_mode = \"sparse\",\n","                                                target_size = (256, 256),\n","                                                batch_size = 32,\n","                                                seed = 42,\n","                                                shuffle = False\n","                                                )\n","\n","test_generator = test_gen.flow_from_dataframe(dataframe = test,\n","                                              directory = './Amazon_Bark_Split/test',\n","                                              x_col = 'filename',\n","                                              y_col = 'Specie',\n","                                              class_mode = \"sparse\",\n","                                              target_size = (256, 256),\n","                                              batch_size = 32,\n","                                              seed = 42,\n","                                              shuffle = False\n","                                              )"]},{"cell_type":"markdown","source":["## **ResNet50**"],"metadata":{"id":"Y2M_CH9f3vFE"}},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Carregar o modelo ResNet50 pr√©-treinado com pesos ImageNet\n","#-----------------------------------------------------------------------------#\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"],"metadata":{"id":"SohZpvEoPzKN","executionInfo":{"status":"ok","timestamp":1713033069470,"user_tz":180,"elapsed":9442,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"22058c22-b1e3-4ffd-b8f0-f213a197c654"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94765736/94765736 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Pr√© processamento ResNet\n","#-----------------------------------------------------------------------------#\n","preprocess_resnet = tf.keras.applications.resnet50.preprocess_input"],"metadata":{"id":"Jf-36TcCPudQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Construindo extrator de features ResNet\n","#-----------------------------------------------------------------------------#\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = preprocess_resnet(inputs)\n","x = base_model(x)\n","output = GlobalAveragePooling2D()(x)\n","\n","# Criar um novo modelo para extra√ß√£o de caracter√≠sticas\n","feature_extractor = Model(inputs, output)\n","\n","# Visualizar o resumo do modelo\n","feature_extractor.summary()"],"metadata":{"id":"ce3oQIORP6_E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Extrair caracter√≠sticas das imagens\n","#------------------------------------------------------------------------------#\n","# Train\n","X_train_features = feature_extractor.predict(train_generator)\n","\n","# Test\n","X_test_features = feature_extractor.predict(test_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqzLPlf_QLVf","outputId":"162feeac-e301-4bd8-c1ea-e8f0d3807785","executionInfo":{"status":"ok","timestamp":1713035494609,"user_tz":180,"elapsed":1958348,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["70/70 [==============================] - 1538s 22s/step\n","18/18 [==============================] - 390s 23s/step\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Salvar features\n","#------------------------------------------------------------------------------#\n","\n","np.savez(f'./Output/features_train.npz', X_train = X_train_features, y_train = y_train, sample_train = sample_train)\n","np.savez(f'./Output/features_test.npz', X_test = X_test_features, y_test = y_test, sample_test = sample_test)"],"metadata":{"id":"js01D8RnoPUW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **VGG16**"],"metadata":{"id":"E01nFKWj-SMD"}},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Carregar o modelo VGG16 pr√©-treinado com pesos ImageNet\n","#-----------------------------------------------------------------------------#\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1713054409921,"user_tz":180,"elapsed":7422,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"dba364fe-60ee-4dd6-b57f-399d82d8bb6b","id":"_2H-zAkE4rSX"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Pr√© processamento VGG16\n","#-----------------------------------------------------------------------------#\n","preprocess_vgg16 = tf.keras.applications.vgg16.preprocess_input"],"metadata":{"id":"qAEMHmSG9bYo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Construindo extrator de features VGG16\n","#-----------------------------------------------------------------------------#\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = preprocess_vgg16(inputs)\n","x = base_model(x)\n","output = GlobalAveragePooling2D()(x)\n","\n","# Criar um novo modelo para extra√ß√£o de caracter√≠sticas\n","feature_extractor = Model(inputs, outputs=output)\n","\n","# Visualizar o resumo do modelo\n","feature_extractor.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sCqaoKxN4rSZ","executionInfo":{"status":"ok","timestamp":1713056134950,"user_tz":180,"elapsed":524,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"outputId":"a7c21002-87a2-4816-997b-d01c1e817c79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," tf.__operators__.getitem_1  (None, 224, 224, 3)       0         \n","  (SlicingOpLambda)                                              \n","                                                                 \n"," tf.nn.bias_add_1 (TFOpLamb  (None, 224, 224, 3)       0         \n"," da)                                                             \n","                                                                 \n"," vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n","                                                                 \n"," global_average_pooling2d (  (None, 512)               0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n","=================================================================\n","Total params: 14714688 (56.13 MB)\n","Trainable params: 0 (0.00 Byte)\n","Non-trainable params: 14714688 (56.13 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Extrair caracter√≠sticas das imagens\n","#------------------------------------------------------------------------------#\n","# Train\n","X_train_features = feature_extractor.predict(train_generator)\n","\n","# Test\n","X_test_features = feature_extractor.predict(test_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e2448884-3407-426c-80c7-012f6c6b8b68","executionInfo":{"status":"ok","timestamp":1713057318121,"user_tz":180,"elapsed":1168008,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"id":"6PotkVVF4rSa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["70/70 [==============================] - 677s 10s/step\n","18/18 [==============================] - 443s 26s/step\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Salvar features\n","#------------------------------------------------------------------------------#\n","\n","np.savez(f'./Output/CNN/Features/features_vgg16_train.npz', X_train = X_train_features, y_train = y_train, sample_train = sample_train)\n","np.savez(f'./Output/CNN/Features/features_vgg_16test.npz', X_test = X_test_features, y_test = y_test, sample_test = sample_test)"],"metadata":{"id":"LcvipV9B4rSa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Inception**"],"metadata":{"id":"wOyXoa58DYER"}},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Carregar o modelo InceptionV3 pr√©-treinado com pesos ImageNet\n","#-----------------------------------------------------------------------------#\n","base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1713057579629,"user_tz":180,"elapsed":3552,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f05688f9-144a-4749-eee0-635310c6b6dd","id":"c2vLnfSoD1De"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87910968/87910968 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Pr√© processamento InceptionV3\n","#-----------------------------------------------------------------------------#\n","preprocess_inception = tf.keras.applications.inception_v3.preprocess_input"],"metadata":{"id":"rXoAE80_D1Dy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Construindo extrator de features InceptionV3\n","#-----------------------------------------------------------------------------#\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = preprocess_inception(inputs)\n","x = base_model(x)\n","output = GlobalAveragePooling2D()(x)\n","\n","# Criar um novo modelo para extra√ß√£o de caracter√≠sticas\n","feature_extractor = Model(inputs, outputs=output)\n","\n","# Visualizar o resumo do modelo\n","feature_extractor.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713057666825,"user_tz":180,"elapsed":478,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"outputId":"2f074fdf-bfed-4be1-9028-33e61b092677","id":"pYv0ugR3D1Dz"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," tf.math.truediv_1 (TFOpLam  (None, 224, 224, 3)       0         \n"," bda)                                                            \n","                                                                 \n"," tf.math.subtract_1 (TFOpLa  (None, 224, 224, 3)       0         \n"," mbda)                                                           \n","                                                                 \n"," inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n","                                                                 \n"," global_average_pooling2d_1  (None, 2048)              0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n","=================================================================\n","Total params: 21802784 (83.17 MB)\n","Trainable params: 0 (0.00 Byte)\n","Non-trainable params: 21802784 (83.17 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Extrair caracter√≠sticas das imagens\n","#------------------------------------------------------------------------------#\n","# Train\n","X_train_features = feature_extractor.predict(train_generator)\n","\n","# Test\n","X_test_features = feature_extractor.predict(test_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f1ba61f4-9a98-41e2-8f63-d079770e63d9","id":"cJrl2HvxD1Dz","executionInfo":{"status":"ok","timestamp":1713058446462,"user_tz":180,"elapsed":694392,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["70/70 [==============================] - 533s 8s/step\n","18/18 [==============================] - 146s 8s/step\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Salvar features\n","#------------------------------------------------------------------------------#\n","\n","np.savez(f'./Output/CNN/Features/features_inception_train.npz', X_train = X_train_features, y_train = y_train, sample_train = sample_train)\n","np.savez(f'./Output/CNN/Features/features_inception_16test.npz', X_test = X_test_features, y_test = y_test, sample_test = sample_test)"],"metadata":{"id":"PXusmwOlD1Dz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **MobileNet_V2**"],"metadata":{"id":"xfCWAspXQCAA"}},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Carregar o modelo MobileNetV2 pr√©-treinado com pesos ImageNet\n","#-----------------------------------------------------------------------------#\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1713058723999,"user_tz":180,"elapsed":1773,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1eb4c938-ea8c-4fe2-8b04-69cb69a02e43","id":"qvSOyNnkQMbo"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n","9406464/9406464 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Pr√© processamento MobileNetV2\n","#-----------------------------------------------------------------------------#\n","preprocess_mobile = tf.keras.applications.mobilenet_v2.preprocess_input"],"metadata":{"id":"j31JLhyrQMbq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Construindo extrator de features MobileNetV2\n","#-----------------------------------------------------------------------------#\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = preprocess_mobile(inputs)\n","x = base_model(x)\n","#output = Flatten()(x)\n","output = GlobalAveragePooling2D()(x)\n","\n","# Criar um novo modelo para extra√ß√£o de caracter√≠sticas\n","feature_extractor = Model(inputs, outputs=output)\n","\n","# Visualizar o resumo do modelo\n","feature_extractor.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713058857046,"user_tz":180,"elapsed":1173,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"outputId":"1f2e73f5-94d7-4e6f-bc4b-e525df30ad0d","id":"gbL7dheZQMbq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_9 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," tf.math.truediv_3 (TFOpLam  (None, 224, 224, 3)       0         \n"," bda)                                                            \n","                                                                 \n"," tf.math.subtract_3 (TFOpLa  (None, 224, 224, 3)       0         \n"," mbda)                                                           \n","                                                                 \n"," mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n"," tional)                                                         \n","                                                                 \n"," global_average_pooling2d_2  (None, 1280)              0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n","=================================================================\n","Total params: 2257984 (8.61 MB)\n","Trainable params: 0 (0.00 Byte)\n","Non-trainable params: 2257984 (8.61 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Extrair caracter√≠sticas das imagens\n","#------------------------------------------------------------------------------#\n","# Train\n","X_train_features = feature_extractor.predict(train_generator)\n","\n","# Test\n","X_test_features = feature_extractor.predict(test_generator)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"76a515dc-f8f8-4760-a8ab-f31b9d2bb4e0","executionInfo":{"status":"ok","timestamp":1713059612795,"user_tz":180,"elapsed":710054,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"id":"kgOwqFgGQMbq"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["70/70 [==============================] - 543s 8s/step\n","18/18 [==============================] - 152s 9s/step\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Salvar features\n","#------------------------------------------------------------------------------#\n","\n","np.savez(f'./Output/CNN/Features/features_mobnet_train.npz', X_train = X_train_features, y_train = y_train, sample_train = sample_train)\n","np.savez(f'./Output/CNN/Features/features_mobnet_test.npz', X_test = X_test_features, y_test = y_test, sample_test = sample_test)"],"metadata":{"id":"Y-WrSWJuQMbq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **4- Extraindo caracteristicas dos patches**"],"metadata":{"id":"bDDVbqh6vHyj"}},{"cell_type":"markdown","source":["## **Carregando dados**\n","\n","A base de dados dos patches possui 111.850 patches de treinamento, e 28.300 patches de teste. Para otimizar o processamento foi utilizada uma estrat√©gia de distribui√ß√£o de tpu."],"metadata":{"id":"Wb0dKv5s-Cwk"}},{"cell_type":"code","source":["#===============================================================================\n","# Extrat√©gia de distribui√ß√£o de TPU para patches\n","#===============================================================================\n","print(\"Tensorflow version \" + tf.__version__)\n","\n","try:\n","  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","  print(f'Running on a TPU w/{tpu.num_accelerators()[\"TPU\"]} cores')\n","except ValueError:\n","  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n","\n","tf.config.experimental_connect_to_cluster(tpu)\n","tf.tpu.experimental.initialize_tpu_system(tpu)\n","tpu_strategy = tf.distribute.TPUStrategy(tpu)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713060650217,"user_tz":180,"elapsed":11557,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"outputId":"b16c6e9c-3cd7-4d0f-8c17-e2f74001d1c5","id":"2kMWrf2OFtmy"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow version 2.15.0\n","Running on a TPU w/8 cores\n"]}]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Carregar o arquivo .npz\n","#-----------------------------------------------------------------------------#\n","with np.load('./Output_patches/patches_and_labels_train.npz', mmap_mode= 'r', allow_pickle=True) as f:\n","    X_train = f['patches']\n","    y_train = f['labels']\n","\n","with np.load('./Output_patches/patches_and_labels_test.npz', mmap_mode= 'r', allow_pickle=True) as f:\n","    X_test = f['patches']\n","    y_test = f['labels']"],"metadata":{"id":"dkqsrmuSuF4r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Obtendo labels - Train\n","#-----------------------------------------------------------------------------#\n","lab = []\n","for label in range(len(y_train)):\n","  split = y_train[label].split('_')\n","  path = split[0]\n","  specie = int(split[2])\n","  sample = int(split[4])\n","  code = split[6].split('.')[0]\n","  dev = split[5]\n","  lab.append([path, specie, sample, code, dev])\n","\n","labels_train = pd.DataFrame(lab, columns= ['Patch','Specie', 'Sample', 'Id', 'Dev'])\n","df = pd.read_csv('./Class.csv', sep = ';')\n","labels_train['Specie'] = labels_train['Specie'].map(df.set_index('Code')['Specie'])\n","labels_train"],"metadata":{"id":"jAGHpcYPIXuc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Obtendo labels - Test\n","#-----------------------------------------------------------------------------#\n","lab = []\n","for label in range(len(y_test)):\n","  split = y_test[label].split('_')\n","  path = split[0]\n","  specie = int(split[2])\n","  sample = int(split[4])\n","  code = split[6].split('.')[0]\n","  dev = split[5]\n","  lab.append([path, specie, sample, code, dev])\n","\n","labels_test = pd.DataFrame(lab, columns= ['Patch','Specie', 'Sample', 'Id', 'Dev'])\n","df = pd.read_csv('./Class.csv', sep = ';')\n","labels_test['Specie'] = labels_test['Specie'].map(df.set_index('Code')['Specie'])\n","labels_test"],"metadata":{"id":"4FGCjfuUwcle"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **ResNet50**"],"metadata":{"id":"nDDuKQWt-HXT"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"SymbFwsTXm35"},"outputs":[],"source":["#-----------------------------------------------------------------------------#\n","# Carregar o modelo ResNet50 pr√©-treinado com pesos ImageNet\n","#-----------------------------------------------------------------------------#\n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Construindo extrator de features ResNet\n","#-----------------------------------------------------------------------------#\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = preprocess_resnet(inputs)\n","x = base_model(x)\n","output = GlobalAveragePooling2D()(x)\n","\n","# Criar um novo modelo para extra√ß√£o de caracter√≠sticas\n","feature_extractor = Model(inputs, output)\n","\n","# Visualizar o resumo do modelo\n","feature_extractor.summary()"],"metadata":{"id":"h67LfDJZvttY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train\n","with tpu_strategy.scope():\n","  # Extrair caracter√≠sticas das imagens\n","  X_train_resize = tf.image.resize(X_train, (224, 224))\n","  X_train_preprocessed = preprocess_resnet(X_train_resize)\n","  X_train_features = feature_extractor.predict(X_train_preprocessed)\n","\n","# test\n","with tpu_strategy.scope():\n","  # Extrair caracter√≠sticas das imagens\n","  X_test_resize = tf.image.resize(X_test, (224, 224))\n","  X_test_preprocessed = preprocess_resnet(X_test_resize)\n","  X_test_features = feature_extractor.predict(X_test_preprocessed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bn2KSZjC2q6b","executionInfo":{"status":"ok","timestamp":1712957568503,"user_tz":180,"elapsed":1015328,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"outputId":"faec2c22-0514-4ed7-cfde-d7b479abdea0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3496/3496 [==============================] - 647s 180ms/step\n","885/885 [==============================] - 157s 177ms/step\n"]}]},{"cell_type":"code","source":["np.savez(f'./Output_patches/Features/patches_resnet_train.npz', X_train = X_train_features, y_train = labels_train)\n","np.savez(f'./Output_patches/Features/patches_resnet_test.npz', X_test = X_test_features, y_test = labels_test)"],"metadata":{"id":"b5yDYWzTLQ2p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **VGG16**"],"metadata":{"id":"RXkgzNMS-LpP"}},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Carregar o modelo VGG16 pr√©-treinado com pesos ImageNet\n","#-----------------------------------------------------------------------------#\n","base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"],"metadata":{"id":"1eJSZ4_vYF4I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Pr√© processamento VGG16\n","#-----------------------------------------------------------------------------#\n","preprocess_vgg16 = tf.keras.applications.vgg16.preprocess_input"],"metadata":{"id":"DtW6NyHnYF4K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Construindo extrator de features VGG16\n","#-----------------------------------------------------------------------------#\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = preprocess_vgg16(inputs)\n","x = base_model(x)\n","output = GlobalAveragePooling2D()(x)\n","\n","# Criar um novo modelo para extra√ß√£o de caracter√≠sticas\n","feature_extractor = Model(inputs, outputs=output)\n","\n","# Visualizar o resumo do modelo\n","feature_extractor.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713061463215,"user_tz":180,"elapsed":430,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"outputId":"1344c5db-8b81-41ee-cb6e-70fcd1001ca2","id":"BANZKUwAYF4K"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," tf.__operators__.getitem (  (None, 224, 224, 3)       0         \n"," SlicingOpLambda)                                                \n","                                                                 \n"," tf.nn.bias_add (TFOpLambda  (None, 224, 224, 3)       0         \n"," )                                                               \n","                                                                 \n"," vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n","                                                                 \n"," global_average_pooling2d (  (None, 512)               0         \n"," GlobalAveragePooling2D)                                         \n","                                                                 \n","=================================================================\n","Total params: 14714688 (56.13 MB)\n","Trainable params: 0 (0.00 Byte)\n","Non-trainable params: 14714688 (56.13 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Extrair caracter√≠sticas das imagens\n","#------------------------------------------------------------------------------#\n","# train\n","with tpu_strategy.scope():\n","  # Extrair caracter√≠sticas das imagens\n","  X_train_resize = tf.image.resize(X_train, (224, 224))\n","  X_train_features = feature_extractor.predict(X_train_resize)\n","\n","#test\n","with tpu_strategy.scope():\n","  # Extrair caracter√≠sticas das imagens\n","  X_test_resize = tf.image.resize(X_test, (224, 224))\n","  X_test_features = feature_extractor.predict(X_test_resize)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c4ee58f-1753-48eb-85ce-b1f698a31808","executionInfo":{"status":"ok","timestamp":1713063763171,"user_tz":180,"elapsed":501647,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"id":"vTURm6eAYF4K"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3496/3496 [==============================] - 249s 71ms/step\n","885/885 [==============================] - 64s 72ms/step\n"]}]},{"cell_type":"code","source":["np.savez(f'./Output_patches/CNN/Features/patches_vgg16_train.npz', X_train = X_train_features, y_train = labels_train)\n","np.savez(f'./Output_patches/CNN/Features/patches_vgg16_test.npz', X_test = X_test_features, y_test = labels_test)"],"metadata":{"id":"-BdeBRzPYXmz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Inception**"],"metadata":{"id":"cp-HsKD0n4Qi"}},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Carregar o modelo InceptionV3 pr√©-treinado com pesos ImageNet\n","#-----------------------------------------------------------------------------#\n","base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"],"metadata":{"id":"tzBHTlRin4Qi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Pr√© processamento InceptionV3\n","#-----------------------------------------------------------------------------#\n","preprocess_inception = tf.keras.applications.inception_v3.preprocess_input"],"metadata":{"id":"hD0UE1yPn4Qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Construindo extrator de features InceptionV3\n","#-----------------------------------------------------------------------------#\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = preprocess_inception(inputs)\n","x = base_model(x)\n","output = GlobalAveragePooling2D()(x)\n","\n","# Criar um novo modelo para extra√ß√£o de caracter√≠sticas\n","feature_extractor = Model(inputs, outputs=output)\n","\n","# Visualizar o resumo do modelo\n","feature_extractor.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713065041607,"user_tz":180,"elapsed":1157,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"outputId":"cca9c42a-722a-4bfa-ce83-3dc12fd4f550","id":"e9cjEJo3n4Qj"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," tf.math.truediv (TFOpLambd  (None, 224, 224, 3)       0         \n"," a)                                                              \n","                                                                 \n"," tf.math.subtract (TFOpLamb  (None, 224, 224, 3)       0         \n"," da)                                                             \n","                                                                 \n"," inception_v3 (Functional)   (None, 5, 5, 2048)        21802784  \n","                                                                 \n"," global_average_pooling2d_1  (None, 2048)              0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n","=================================================================\n","Total params: 21802784 (83.17 MB)\n","Trainable params: 0 (0.00 Byte)\n","Non-trainable params: 21802784 (83.17 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Extrair caracter√≠sticas das imagens\n","#------------------------------------------------------------------------------#\n","# train\n","with tpu_strategy.scope():\n","  # Extrair caracter√≠sticas das imagens\n","  X_train_resize = tf.image.resize(X_train, (224, 224))\n","  X_train_features = feature_extractor.predict(X_train_resize)\n","\n","#test\n","with tpu_strategy.scope():\n","  # Extrair caracter√≠sticas das imagens\n","  X_test_resize = tf.image.resize(X_test, (224, 224))\n","  X_test_features = feature_extractor.predict(X_test_resize)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5a74c333-e4dd-4a95-f230-da614a941030","executionInfo":{"status":"ok","timestamp":1713066317280,"user_tz":180,"elapsed":1254211,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"id":"FkJ2WWoIn4Qj"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3496/3496 [==============================] - 860s 239ms/step\n","885/885 [==============================] - 207s 233ms/step\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Salvar features\n","#------------------------------------------------------------------------------#\n","\n","np.savez(f'./Output_patches/CNN/Features/patches_inception_train.npz', X_train = X_train_features, y_train = labels_train)\n","np.savez(f'./Output_patches/CNN/Features/patches_inception_test.npz', X_test = X_test_features, y_test = labels_test)"],"metadata":{"id":"bPF48pLRn4Qk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **MobileNet_V2**"],"metadata":{"id":"9YwnhELLtzB9"}},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Carregar o modelo MobileNetV2 pr√©-treinado com pesos ImageNet\n","#-----------------------------------------------------------------------------#\n","base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"],"metadata":{"id":"hPs8uwI4tzCG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Pr√© processamento MobileNetV2\n","#-----------------------------------------------------------------------------#\n","preprocess_mobile = tf.keras.applications.mobilenet_v2.preprocess_input"],"metadata":{"id":"bswFVRnctzCI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-----------------------------------------------------------------------------#\n","# Construindo extrator de features MobileNetV2\n","#-----------------------------------------------------------------------------#\n","inputs = keras.Input(shape=(224, 224, 3))\n","x = preprocess_mobile(inputs)\n","x = base_model(x)\n","#output = Flatten()(x)\n","output = GlobalAveragePooling2D()(x)\n","\n","# Criar um novo modelo para extra√ß√£o de caracter√≠sticas\n","feature_extractor = Model(inputs, outputs=output)\n","\n","# Visualizar o resumo do modelo\n","feature_extractor.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1713067668875,"user_tz":180,"elapsed":944,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"outputId":"773b9a2a-4eac-4396-c741-70a7be5c3aaf","id":"XYo-lX1ptzCJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," tf.math.truediv_1 (TFOpLam  (None, 224, 224, 3)       0         \n"," bda)                                                            \n","                                                                 \n"," tf.math.subtract_1 (TFOpLa  (None, 224, 224, 3)       0         \n"," mbda)                                                           \n","                                                                 \n"," mobilenetv2_1.00_224 (Func  (None, 7, 7, 1280)        2257984   \n"," tional)                                                         \n","                                                                 \n"," global_average_pooling2d_2  (None, 1280)              0         \n","  (GlobalAveragePooling2D)                                       \n","                                                                 \n","=================================================================\n","Total params: 2257984 (8.61 MB)\n","Trainable params: 0 (0.00 Byte)\n","Non-trainable params: 2257984 (8.61 MB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Extrair caracter√≠sticas das imagens\n","#------------------------------------------------------------------------------#\n","# train\n","with tpu_strategy.scope():\n","  # Extrair caracter√≠sticas das imagens\n","  X_train_resize = tf.image.resize(X_train, (224, 224))\n","  X_train_features = feature_extractor.predict(X_train_resize)\n","\n","#test\n","with tpu_strategy.scope():\n","  # Extrair caracter√≠sticas das imagens\n","  X_test_resize = tf.image.resize(X_test, (224, 224))\n","  X_test_features = feature_extractor.predict(X_test_resize)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca2499c7-9e42-4330-9fa7-b90bd193e09c","executionInfo":{"status":"ok","timestamp":1713068443733,"user_tz":180,"elapsed":758035,"user":{"displayName":"Natally Celestino","userId":"00570652130154740621"}},"id":"mAZIMZJQtzCJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3496/3496 [==============================] - 458s 129ms/step\n","885/885 [==============================] - 113s 127ms/step\n"]}]},{"cell_type":"code","source":["#------------------------------------------------------------------------------#\n","# Salvar features\n","#------------------------------------------------------------------------------#\n","\n","np.savez(f'./Output_patches/CNN/Features/patches_mobnet_train.npz', X_train = X_train_features, y_train = labels_train)\n","np.savez(f'./Output_patches/CNN/Features/patches_mobnet_test.npz', X_test = X_test_features, y_test = labels_test)"],"metadata":{"id":"bdrBTx9_tzCJ"},"execution_count":null,"outputs":[]}]}